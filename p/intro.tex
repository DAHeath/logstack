\section{Introduction}\label{sec:intro}

Secure two party computation (2PC) of programs representable as Boolean circuits can be efficiently achieved using garbled circuits (GC).
%
However,  circuit-based MPC in general is problematic because conditional
control flow does not have an efficient circuit representation:
in the cleartext program, only the taken execution is computed whereas in
the circuit \emph{all} branches must be computed.
%While this creates obvious relative overheads in conditional statements, the most significant impact is on general control flow, such as a sequence of loops.

%
Until recently, it was assumed that the players must not only compute
all branches, but also transmit a string of \emph{material} (i.e., the garbled circuit itself) 
proportional to the entire circuit.  
Since communication is the GC bottleneck, transmitting this large string was
problematic for programs with conditionals.

Stacked Garbling~\HK, which we %(and \HK) 
interchangeably call Stacked Garbled Circuit (SGC), shows that
expensive branching-based communication is unnecessary: the players need only
send enough material for the single longest branch. This single
piece of \emph{stacked} material can be re-used across all conditional branches,
substantially reducing communication.
%
Unfortunately, this improvement comes with one important downside:
SGC requires the players to compute more than they would have without stacking.
In particular, for a conditional with $b$ branches, the \HK GC
generator must evaluate under encryption each branch $b-1$ times and
hence must pay $O(b^2)$ total computation.
In contrast, standard garbling uses computation linear in the number
of branches.

In this work, we present a new SGC construction that incurs
only $O(b \log b)$ computation for both players while
retaining the important communication improvement of \HK.
%
The construction also features improved space complexity: while \HK
requires the generator to store $O(b)$ intermediate garblings, both \E and \G in our
construction use only $O(\log b)$ space.
%
Finally, the construction features low constants and hence opens the
door to using SGC even in the presence of high branching factors
without prohibitive computation.
% Next, we argue that
% efficient  support for high branching factor has wide applications in
% MPC.


\subsection{A Case for High Branching Factor}
\label{sec:motivationHighB}

Branching is ubiquitous in programming, and our work significantly
improves the secure evaluation of programs with branching.
Moreover, the efficient support of \emph{high branching factor}
is more important than it may first appear.

Efficient branching
% , such as what is achieved by our work,
enables optimized handling of \emph{arbitrary
control flow}, including repeated and/or nested loops.
%
Specifically, we can repeatedly refactor the source program
until the program is a single loop whose body conditionally dispatches
over straightline fragments of the original program.\footnote{%
  As a brief argument that this is possible, consider that a
  CPU has this structure: in this case the `straightline
  fragments' are the instruction types handled by the CPU.
}
However, these types of refactorings often lead to conditionals with
high branching factor.

As an example,
consider a program $P$ consisting of a loop $L_1$ followed by a loop
$L_2$.  Assume the total number of loop iterations $T$ of $P$ is
known, as is usual in MPC.
For security, we must protect the number of iterations $T_1$ of $L_1$
and $T_2$ of $L_2$.
Implementing such a program with standard Yao GC requires us to
% pay double of the cost achievable with stacked garbling: we must
execute loop $L_1$ $T$ times and then to execute $L_2$ $T$ times.
SGC can simply execute  $\stack(L_1, L_2)$ $T$
times, a circuit with a significantly smaller garbling. This observation corresponds to the
following refactoring:
\[{\tt while (e_0) \{ s_0 \} ; \ while (e_1) \{ s_1 \}}
\longrightarrow {\tt while (e_0 \lor e_1) \{\ if  (e_0) \{s_0\}\  else\  \{s_1\}\ \}} \]
where ${\tt s_i}$ are nested programs and $e_i$ are predicates on program
variables.\footnote{%
  To be pedantic, this specific refactoring is not always
  valid: $\mathtt{s_1}$ might mutate variables used in
  $\mathtt{e_0}$. Still, similar, yet more notationally complex,
  refactorings are always legal.
}
The right hand side is friendlier to SGC, since it
substitutes a loop by a conditional.
Now, consider that $s_0$ and $s_1$ might themselves have conditionals
that can be flattened into a single conditional with all branches.
By repeatedly applying such refactorings, even modest
programs can have conditionals with high branching factors.
High-performance branching, enabled by our approach, allows the
efficient and secure evaluation of such programs.

% In this work, we do not attempt to systematize the possible SGC-based
% optimizations of generic flow control.
In this work, we do not further explore program refactorings as an
optimization.
% consideration 
% , but instead provide a
% powerful approach for handling conditionals, even if they have high
% branching factor.
However, we firmly believe that SGC is an essential tool that will
enable research into this direction, and further believe, as argued
above, that performance in the presence of high branching factor is
essential.




\subsection{\HK and its $O(b^2)$ computation}
\label{sec:bsquaredcost}

Our approach is similar to \HK: we also stack material
to decrease communication.
The key difference is our reduced computation.
It is thus instructive to review \HK,
focusing on the source of its quadratic scaling.

The key idea of SGC is that the circuit generator \G\ garbles,
starting from seeds, each branch $\cir_i$.
He then \emph{stacks} these $b$ garbled circuits, yielding only a
single piece of material proportional to the longest branch: $M =
\bigoplus_i \gcir_i$.\footnote{Note,~\HK, as do we in this work,  pad each GC
material $\gcir_i$ with uniform bits before stacking.  This ensures all
$\gcir_i$ are of the same length.}
Because garblings are expanded from short seeds, the
seeds are compact representations of the garblings.
%
Although it would be insecure for the evaluator \E\ to receive
\emph{all} seeds from \G, \HK\ show that it \emph{is secure} for her
to receive seeds corresponding to the inactive branches.
Let $\aid$ be the id of the active branch.
\E can reconstruct from seeds the garbling of each inactive branch, use XOR to unstack
the material $\gcir_\aid$, and evaluate $\cir_\aid$ normally.
%
Of course, what is described so far is not secure: the above procedure
implies that \E\ knows \aid, which she does not in general
know and which she should not learn.


Thus, \HK\ supplies to \E a `bad' seed for the active branch: i.e.,
she receives a seed that is different yet indistinguishable from the
seed used by \G.
From here, \E
simply \emph{guesses which branch is taken} (she in fact tries  all $b$
branches) and evaluates this guessed branch with the appropriately reconstructed material.
For security, each guess is unverifiable by \E. 
Still, when she guesses right, she indeed evaluates the taken branch and
computes valid GC output labels.
When she guesses wrong, she evaluates the branch
with so-called garbage material (material that is a random-looking string, not
an encryption of circuit truth tables), and computes
\emph{garbage output labels} (i.e., labels that are not the encryption
of $0$ or $1$, but are random-looking strings).
%
To proceed past the exit of the conditional and continue evaluation, it is necessary to
`collect'  these garbage labels by obliviously  discarding them in favor of the valid
labels.\footnote{Of course, the final output labels of the conditional
  are fresh,  such that they cannot be cross-referenced with those
obtained in branch evaluation.}


\HK collect garbage without
interaction using a garbled gadget called a \emph{multiplexer}.
%
The multiplexer can be non-interactively constructed by \G,
but only if he \emph{knows all possible garbage labels}.
Once this is satisfied, it is easy for \G to produce a gadget
(e.g., appropriate garbled translation tables)
that eliminates garbage and propagates the active branch's output
labels.


{\bf \G's Uncertainty.}
It is possible for \G\ to acquire all garbage labels.
\HK achieve this by having \G\ emulate the actions of \E\
 on all inactive branches.
To see how this can be done,
 consider \G's knowledge and uncertainty about the garbled evaluation.
 There are three sources of \G's uncertainty:
\begin{itemize}
  \item The input values to each inactive branch.
    This is the largest source of uncertainty (the number of
    possibilities are exponential in the number of input wires), but
    the easiest to handle.  \HK introduce a simple trick:
    they add an additional garbled gadget, the \emph{demultiplexer},
    that `zeros out' the wires into the inactive branches.
    This fully resolves this source of uncertainty.
  \item The index of the active branch, which we denote by \truth.
  \item \E's guess of the value of \truth, which we denote by \guess.
\end{itemize}

In total, there are $b^2$ $(\truth, \guess)$ combinations.
Crucially, each of these combinations leads to \E\ evaluating a
\emph{unique combination of a circuit and material}.
Hence, there are $b^2$ possible sets of labels ($b(b-1)$ garbage sets of labels and $b$ valid sets of labels)  that the evaluator
can compute.
% one for each combination of $(\truth,\guess)$, the
% active and the incorrectly guessed branches.
%


To acquire all possible garbage labels such that he can build the
garbage collecting multiplexer, the \HK generator assumes an all-zero
inputs for each
inactive branch and emulates ``in his head'' \E's evaluation of all possible (\truth,\guess) combinations.
% must construct all $b(b-1)$ sets of garbage labels,
This requires that \G\ evaluate $b(b-1)$ times on garbage material.
This is the source of the $O(b^2)$ computation.






\input{intuition}


\subsection{Our Contributions}
\label{sec:ourContrib}

% Until recently, it was widely believed that a GC
% proportional to the entire program, including parts of the program
% which are entirely discarded due to conditional branching, must
% be transmitted over a network.
% The breakthrough result of~
\HK shows that GC players need not send a GC
proportional to the entire circuit.
Instead, communication proportional to only the longest program execution
path suffices.
However, their improved communication comes at a cost:
for a conditional $b$ branches, the players
use $O(b^2)$ computation. 

This is a usually a worthwhile trade-off: GC generation is usually
much faster than network transmission (cf. our discussion in~\Cref{sec:whentouse}).
However, as the branching factor grows, computation
can quickly become the bottleneck due to quadratic scaling.
%
Thus, as we argue in~\Cref{sec:motivationHighB},
a more computationally efficient technique
opens exciting possibilities for rich classes of problems.

\medskip
This work presents \ourschemelong, an improvement to SGC that features
improved computation without compromising communication.
Our contributions include:
\begin{itemize}
  \item Improved time complexity.
    % A {\em concretely efficient}  asymptotic
    % improvement to the computational cost of stacked garbling.
    For $b$ branches, \ourschemelong\ reduces time complexity from $O(b^2)$ to
    $O(b \log b)$.
  \item Improved space complexity.
    For $b$ branches, our algorithms require $O(\log b)$ space, an
    improvement from \HK's $O(b)$ requirement.
  \item High concrete performance.
    In total, the players together garble or evaluate the $b$ branches
    a total of $\frac{7}{2} b\log b + 2b$ times.
    %
    These concrete results translate to implementation performance: for fewer
    than $16$ branches, our wall-clock runtime is similar to that
    of \HK. At higher branching factors, we clearly outperform prior
    work (see \Cref{sec:eval}).
  \item
    A formalization in the \cite{CCS:BelHoaRog12} framework (as
    modified by \HK) proved
    secure under standard assumptions.
    \HK proved SGC secure by assuming a random oracle.
    We prove security assuming only a pseudorandom function.
    % Like \HK, we leave the processing of low level gates to an
    % underlying garbling scheme \underscheme.
    % Of course, if \underscheme relies on non-standard assumptions, we
    % can still use \underscheme, but acquire
    % assumptions, in which case \ourschemelong will similarly require
    % them.
\end{itemize}



\subsection{When to use \ourschemelong: a high-level costs consideration}
\label{sec:whentouse}

We now informally discuss a broad question of
practical importance:

\begin{displayquote}
  ``If my program has complex control flow, how can I most efficiently implement it for 2PC?''
\end{displayquote}

To make the question more precise, we assume that `most efficiently' means
`optimized for shortest total wall-clock time'.
% Clearly, since SGC 
Since
(1) GC is often the most practical approach to 2PC,
(2) the GC bottleneck is communication,
(3) `complex control flow' implies conditional behavior, and
(4) SGC improves communication for programs with conditional behavior,
SGC plays an important role in answering this question.
%
Of course, the cryptographic technique is not the only variable
in the optimization space.
Program transformations, such as described
in~\Cref{sec:motivationHighB}, also play a crucial role.
%
These variables are related:
some program transformations may lead to a blowup in the number of
branches.
While SGC alleviates the communication overhead of this blowup, the
players still incur $b \log b$ computational overhead.
%
So choosing which program transformations to apply depends also on the
performance characteristics of the cryptographic scheme.

Despite the fact that the optimization space for total wall-clock time
is complex, we firmly believe the following claim:
using \ourschemelong over standard GC will \emph{almost always improve
  performance.}
The rest of this section argues this claim.

% \paragraph{Assumption: computation vs communication.} 
\paragraph{Computation vs communication.} 
To discuss how to best apply \ourschemelong, we establish
approximate relative costs of GC computation and communication. 

 Based
on our experiments, as well as on~\cite{XiaoPersonalComm}, a commodity
laptop running a single core can generate GC material at about $3\times$ the
network bandwidth of a $1$ Gbps channel.  
However, while 1Gbps is a typical speed in the LAN setting, WAN
speeds are much lower, e.g. $100$Mbps.  Other network speeds
(bluetooth, cellular) are lower still.
Even on a LAN and even in a data center, typically we should
not assume that our MPC application is allowed to consume the entire
channel bandwidth. Rather, we should aim to use as small a fraction of
the bandwidth as possible.  Based on this discussion, and erring on
the conservative side,  we choose $100$Mbps as
``typical'' available bandwidth.
%

Computation is a much more available resource.
Today, commodity laptops have four physical cores. Higher-end computing devices, such as desktop CPUs and GPUs have higher numbers of cores and/or per-core processing power,
resulting in yet higher GC computation-to-transmission ratio.
Precomputation, if available, can also be seen as a way to increase
the available compute resource.
SGC,  even when using our more sophisticated algorithms, is highly parallelizable.
%f the GC includes conditional branching, 
It is easy to
engage \emph{many} cores to achieve proportional performance improvement.
%(handling of conditional branchesis \emph{highly} parallelizable, even when using our more sophisticated SGC algorithms).
%
Based on this discussion, and erring on the conservative side, we choose $2$ physical cores as a lower end of ``typical'' available computational power. 

Given a typical setting with $2$ cores and a
$100$Mbps channel, we arrive at an approximation that GC computation
is $\approx 60 \times$ faster than GC transmission.
%

%
%

% We assume 
% material can be transmitted while it is generated, and the wall clock time is the maximum of generation and transmission times.

%Based on the above, we argue that typical settings allow that the material computing device is (only) $24\times$ faster than the material transmission device.




\paragraph{Assumption: fixed target circuit}
To gain a foothold on answering our broad question, we start by ruling
out program transformations and consider only cryptographic protocols.
Thus, we consider a fixed {\em baseline circuit} against which we
measure SGC and \ourschemelong\ performance.    That is, our baseline is a
circuit \cir\ with conditionals, to which we apply garbling scheme
directly, and to which we do not apply any program transformations.
We may compare 2PC based on \ourschemelong with  Yao GC, both instantiated
with half-gates~\cite{EC:ZahRosEva15}.



\paragraph{Rule of thumb: Always apply \ourschemelong.}  Assuming our
approximated speed ratio of GC generation/transmission, and with a few caveats
described next, using \ourschemelong\ for branching will {\em always}
improve over standard GC. 

This is easy to see.
% Indeed, we evaluate a given \cir\ as-is.
\G and \E together 
run a more computationally demanding  process, garbling and evaluating 
%and efficiently combining
branches exactly $\frac{7}{2} b \log b + 2b$ total times ($\frac{5}{2} b \log b + b$ garblings and $ b \log b + b$  evaluations).  Consider a
conditional with $b$ branches.  Classic GC will transmit $b$ branches.
During this time, \G and \E could have instead performed $60 b$ branch garbling/evaluations. 
\ourschemelong  garbles/evaluates $\frac{7}{2} b \log b$ branches.  Thus,  the point where
computation crosses over to become the bottleneck is obtained by
solving $\frac{7}{2}b \log b > 60 b$, the solution to which is $b \gtrapprox 2^{17} = 131072$
branches.  Of course, this is a ``rule-of-thumb'' estimate and is based on the conservative assumptions discussed above.

If instead a full 1Gbps channel is available (i.e. $10\times$ of our network resource assumption),  to arrive at the same cross over  point, we would need ten times more cores than our computational resource assumption.  That equates to $20$ cores; such power is available on mainstream servers.

We conclude that applying \ourschemelong\ improves wall clock
time for nearly all reasonable baseline circuits and settings.


\paragraph{Limits on circuit transformations imposed by computational costs.}
Above, we established that \ourschemelong\ is almost always
better than standard GC for circuits with branching.
%
It is harder to provide heuristics or
even rough suggestions regarding which circuit transformations (cf.
in~\Cref{sec:motivationHighB}) to apply, and how aggressively
they should be applied in conjunction with \ourschemelong\ secure evaluation.  We
emphasize that our computational improvement opens
a {\em much} wider optimization space than what was possible with the
prior scheme~\HK.  We leave detailed investigation into this direction
as exciting future work.





