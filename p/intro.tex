\section{Introduction}\label{sec:intro}

Secure two party computation (2PC) of programs representable as Boolean circuits can be efficiently achieved using garbled circuits (GC).
%
However,  circuit-based MPC in general is problematic because conditional
control flow does not have an efficient circuit representation:
in the cleartext program, only the taken execution is computed whereas in
the circuit \emph{all} branches must be computed.
%While this creates obvious relative overheads in conditional statements, the most significant impact is on general control flow, such as a sequence of loops.

%
Until recently, it was assumed that the players must not only compute
all branches, but also transmit a string of \emph{material} (i.e., the garbled circuit itself) 
proportional to the entire circuit.  
Since communication is the bottleneck in GC, transmitting this large string was
problematic for programs with conditional behavior.

Stacked Garbling~\HK, which we %(and \HK) 
interchangeably call Stacked Garbled Circuit (SGC), shows that
this expensive branching-based communication blow-up is unnecessary: the players need only
send enough material for the single longest branch. This single
piece of \emph{stacked} material can be re-used across all conditional branches, thus
dramatically reducing communication cost.
%
This improvement does come with one important downside:
Stacked Garbling requires the players to compute far more than they
would have without stacking.
In particular, for a conditional with branching factor $b$, the \HK GC
generator must evaluate each branch under encryption $b-1$ times, and
he hence pays $O(b^2)$ total computation.
In contrast, standard garbling uses computation linear in the number
of branches.

In this work, we present a new construction for SGC that incurs
only $O(b \log b)$ computation for both players while
retaining the important communication improvement of \HK.
%
The construction also features low constants, and hence opens the door
to using SGC even in the presence of very high branching factors
without computation becoming prohibitive.  Next, we argue that efficient  support for high branching factor has wide applications in MPC.


\subsection{A case for a high branching factor}
\label{sec:motivationHighB}

Clearly, conditional branching is ubiquitous in programming, and our work significantly
improves the secure evaluation of programs with
branching.
Moreover, the efficient support for programs with \emph{high branching factor}
is more important than it may first appear.

Our main observation is that free/cheap branching, such as what is
achieved by our work, enables optimized handling of \emph{arbitrary
control flow}, including arbitrary repeated and/or nested loops.
%
Specifically, we can repeatedly \emph{refactor} the source program
until the program is a single loop whose body conditionally dispatches
over straightline fragments of the original program\footnote{%
  As a brief argument that this is clearly possible, consider that a
  CPU has this exact structure: in this case the `straightline
  fragments' are the individual instruction types handled by the CPU.
}.
However, these types of refactorings often lead to conditionals with
high branching factor.

As a simple example,
consider a program $P$ consisting of a loop $L_1$ followed by a loop
$L_2$.  Assume the total upper bound on runtime (total number of loop
iterations $T$) of $P$ is known, as is usual in MPC.
For security, we must protect the number of iterations $T_1$ of $L_1$
and $T_2$ of $L_2$.
Implementing such a program with standard Yao GC requires us to
pay double of the cost achievable with stacked garbling: we must
execute loop $L_1$ $T$ times followed by executing $L_2$ $T$ times.
At the same time, SGC can simply execute  $\stack(L_1, L_2)$ $T$
times, a circuit with a significantly smaller garbling. This observation corresponds to the
following refactoring:
\[{\tt while (e_0) \{ s_0 \} ; \ while (e_1) \{ s_1 \}}
\longrightarrow {\tt while (e_0 \lor e_1) \{\ if  (e_0) \{s_0\}\  else\  \{s_1\}\ \}} \]
where ${\tt s_i}$ are nested programs and $e_i$ are predicates on program
variables.
Note that the result of this transformation is friendlier to SGC, 
%secure computation setting,
 since we have reduced the number of loops,
but have introduced a conditional.
Now, consider that $s_0$ and $s_1$ might themselves have conditionals
that can now be flattened into a single conditional with all branches.
By repeatedly applying refactorings like this one, even modest
programs can have conditionals with very high branching factors.
High-performance branching, enabled by our approach, will allow the
efficient and secure evaluation of such programs.

% Let's take this a step further, and consider the following program $P$ still bounded by $T$ total iterations of the inner loops:
% \[{\tt loop_{T_0}\ \{ loop_{T_1} \{ s_0 \};\ s_2;\  loop_{T_2} \{ s_1 \}\ \} }.\] 
% This program can be still be rewritten as  
% \[{\tt loop_{T} \{\ switch  (cond):\{ s_0\ |\ s_1\ |\ s_2\ |\ \mathtt{no-op}\}\ \}},\] 
% saving up to a factor $2T_0\times$ when evaluated with stacked garbling. \vlad{Here I want to add $s_i$ at i-th iteration of outer loop, so that our stacked program will have to have many branches.}

In this work, we do not attempt to systematize the possible SGC-based
optimizations of the generic flow control.
% , but instead provide a
% powerful approach for handling conditionals, even if they have high
% branching factor.
However, we firmly believe that SGC is an essential tool that will
enable research into this direction, and further believe, as argued
above, that performance in the presence of high branching factor is
essential.





 




\subsection{Source of $O(b^2)$ Computation Cost of \HK Stacked Garbling }
\label{sec:bsquaredcost}

It is instructive to explain the source of quadratic SGC computation of \HK, to help explain our work.

At a high level, the fundamental idea of Stacked Garbling is that the evaluator \E
guesses which branch is taken (she in fact tries  all $b$
branches) and evaluates this guessed branch with the appropriately reconstructed material.  Of course, for security, the guess is unverifiable by \E. 
Still, when she guesses right, she indeed evaluates the taken branch and
computes valid GC output labels for that branch.
However, when she guesses wrong, she ends up evaluating the branch
with so-called garbage material (material that is a random-looking string, not
an encryption of circuit truth tables), and ends up computing
\emph{garbage output labels} (i.e., labels that are not the encryption
of $0$ or $1$, but are instead random-looking strings).
%
To proceed past the exit of the conditional and continue garbled evaluation, it is necessary to
`collect'  these garbage labels, i.e., obliviously  discard them in favor of the valid
labels.  (Of course, the final output labels of the conditional will be fresh,  so that they cannot be cross-referenced with those obtained in branch evaluation.)


\HK show how to collect this garbage without
interaction using a 
%.  The main idea is to require SGC Generator \G to construct 
multiplexer garbled gadget, constructed by the SGC Generator \G.  
Building the \HK multiplexer requires \G to {\em know all possible
garbage labels} the evaluator might obtain.  Once this is satisfied, it is easy to see how \G can produce a gadget (e.g., an appropriately wired set of garbled translation tables) eliminating garbage and propagating true values.


{\bf The Uncertainty of \G.}
It is possible for generator to acquire these garbage labels.  \HK achieve this by having \G  emulate the actions of the
evaluator \E on all non-taken branches.  To see how this can be done, let's consider \G's knowledge and uncertainty about the garbled evaluation.  There are three sources of \G's uncertainty:
\begin{itemize}
	\item True values of inputs of all branches.  This is the largest uncertainty (exponential number of possibilities in the number of inputs to the conditional), and the easiest to deal with.  \HK introduce a simple and elegant trick of the circuit simply setting to a fixed value, e.g., all zeros, all the inputs to the inactive branches.  This fully resolves this kind of uncertainty wrt \G.
	\item True index of the actually taken branch, which we denote by \truth.
	\item \E's guess of value of \truth, which we denote by \guess.
\end{itemize}

Thus, there are $b^2$   sets of labels (including  $b(b-1)$ garbage sets of labels and $b$ valid sets of labels)  that the evaluator
could arrive at: one for each combination of (\truth,\guess), the  actually taken  and
the incorrectly guessed branches. \vlad{is this correct: we have $b$ valid sets of labels?  also call them sets or pairs? decide on notation here.}
%


To aquire all possible garbage labels (and hence build the multiplexer for garbage collection), the \HK generator assumes all-zero inputs for non-taken branches, and emulates ``in its head'' \E's evaluation under all possible (\truth,\guess) combinations.  
% must construct all $b(b-1)$ sets of garbage labels,
This requires \G evaluate GC (i.e. call \Ev) $b(b-1)$ times on garbage material.
This is the source of the $O(b^2)$ computation.



\input{intuition}


\subsection{Our Contributions}
\label{sec:ourContrib}

Until recently, it was widely believed that a GC
proportional to the entire program, including parts of the program
which are entirely discarded due to conditional branching, must
be transmitted over a network.
Breakthrough result~\HK shows that this belief is \emph{false}, and that instead
communication proportional only to the longest program execution
path suffices.  However, this comes with a cost:
for a circuit with conditional branching factor $b$, the players in~\HK 
perform $O(b^2)$ computation.  Namely, in~\HK GC generator garbles $b^2$ branches at the cost $O(b^2|C|)$  instead of $b$ branches garbled in traditional GC at the cost $O(b|C|)$.

This is a worthy trade-off: GC generation speed is usually much higher than network speeds (cf. our discussion in~\Cref{sec:whentouse}).  However, as we argue in~\Cref{sec:motivationHighB}, 
a more computationally efficient stacking
%, beyond the obvious improvement for 
opens exciting possibilities for applying rich classes of program transformations.   




\medskip
Our contributions:
\begin{itemize}
	\item We provide a {\em concretely efficient}  asymptotic  improvement to the computational cost of stacked garbling.  For $b$ conditional branches, our scheme, \ourschemelong (or \ourscheme),  reduces the cost of garbling  from $O(b^2|C|)$ to $O(b \log b |C|)$. \vlad{concrete numbers}
	\item \ourschemelong has high memory efficiency, both in terms of memory required for garbling, and in the number of accesses.   This is much more efficient than~\HK... \vlad{compare to HK20.  Probably worth writing a subsection.}
	\item While~\HK work in RO model, we show how to remove this assumption and work in the standard model. Of course, an underlying \underscheme may use RO or other assumptions, in which case \ourschemelong will similarly require them
\end{itemize}














\subsection{When to use \ourscheme: Computational constraints on branching factor}
\label{sec:whentouse}

In this section, we discuss what practical constraints are effected by the computational cost of our scheme.  
Our ultimate goal is to optimize the total wall clock time for GC evaluation of the computed function.  The optimization space includes function transformations such as those described in~\Cref{sec:motivationHighB}, weighed against the somewhat increased computational cost of $b\log b$.

% Clearly,  and the  implied upper bound on branching factor and program transformations we may wish to apply prior to 

\paragraph{Assumption: speed of GC generation vs transmission.}  To discuss the best strategy for applying \ourscheme, we must establish approximate relative costs of GC generation and transmission.  Based on our experiments, as well as on~\cite{XiaoPersonalComm}, a commodity laptop running a single core can generate GCs at about $3\times$ the network bandwidth of $1$ Gbps channel.  Engaging  $8$ virtual cores, a typical configuration on a mid-range laptop, would imply up to $\approx 24\times$ higher GC generation speed vs transmission.   At the same time, while 1Gbps is a typical speed in the LAN setting, WAN speeds are much lower, e.g. 100Mbps.  Of course, higher-end computing devices, such as desktop CPUs and GPUs have higher numbers of cores and/or per-core processing power, resulting in yet higher GC computation-to-transmission ratio.  Availability of precomputation (our \G is costlier than \E) and parallelization are additional factors.  
We assume 
%GC material streaming is imlpemented:  
material can be transmitted while it is generated, and the wall clock time is the maximum of generation and transmission times.

Based on the above, we can conservatively set that computing device is (only) $24\times$ faster than the transmission device.




\paragraph{Evaluation approach.}  It is natural to approach this evaluation by considering the {\em baseline circuit} against which we measure SGC and \ourscheme\ performance.    That is, our baseline is a circuit \cir\ with conditionals, to which we apply garbling scheme directly, and to which we do not apply any program transformations.  We may compare 2PC based on \ourscheme with  Yao GC, both instantiated with base scheme half-gates~\cite{EC:ZahRosEva15}.



\paragraph{Rule of thumb: Always apply \ourscheme.}  Assuming the speed ratio of GC generation/transmission, and with a few caveats described next, using \ourscheme\ for branching will {\em always} improve over standard GC. 

This is easy to see.  Indeed, we evaluate a given \cir\ as-is.  \G runs a more computationally demanding  process, garbling and efficiently combining exactly $2 b \log b$ branches.  Consider a conditional with $b$ branches.  Classic GC will transmit $b$ branches.  During this time, \G could perform $24 b$ branch garblings. Since \ourscheme's \G garbles $2\log b$ branches, the point where computation will cross over to become a bottleneck is $2^{12} = 4096$ branches.  We conclude that applying \ourscheme\ improves wal clock time for nearly all reasonable baseline circuits and settings.


\paragraph{Limits on circuit transformations imposed by computational costs.}
Above we have easily  established that \ourscheme\ is almost always better than standard GC.   It is much harder to provide heuristics or a rough suggestions for which circuit transformations (cf. in~\Cref{sec:motivationHighB}) to apply, and how aggressively should they be applied in conjunction with \ourscheme\ secure evaluation.  We emphasize that our computational performance improvement of SGC opens a {\em much} wider optimization space than what was possible with the prior scheme~\HK.  We leave detailed investigation of this direction as exciting future work.





