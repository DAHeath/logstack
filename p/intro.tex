\section{Introduction}\label{sec:intro}

Secure two party computation (2PC) of programs representable as Boolean circuits can be efficiently achieved using garbled circuits (GC).
%
However,  circuit-based MPC in general is problematic because conditional
control flow does not have an efficient circuit representation:
in the cleartext program, only the taken execution is computed whereas in
the circuit \emph{all} branches must be computed.
%While this creates obvious relative overheads in conditional statements, the most significant impact is on general control flow, such as a sequence of loops.

%
Until recently, it was assumed that the players must not only compute
all branches, but also transmit a string of \emph{material} (e.g., the garbled circuit itself) 
proportional to all branches.  
Since communication is the bottleneck in GC, transmission of this large string was
problematic for programs with conditional behavior.

Stacked Garbling~\HK, which we (and \HK)  interchangeably call Stacked Garbled Circuit (SGC), shows that
this expensive branching-based communication blow-up is unnecessary: the players need only
send enough material for the single longest branch. This single
piece of \emph{stacked} material can be re-used across all conditional branches, thus
dramatically reducing communication cost.
%
This improvement does come with one important downside:
Stacked Garbling requires the players to compute far more than they
would have without stacking.
In particular, in a conditional with branching factor $b$, \HK GC generator garbles $b^2$ branches and hence pays $O(b^2)$ computation.  In contrast, standard garbling garbles each branch only once.


\subsection{A case for a high branching factor}
\label{sec:motivationHighB}

Clearly,   branching is an essential feature in programming, and our work significantly improves the efficiency to secure evaluations of programs with branching.
We wish to point out that the efficient support of programs with high branching factor is much more important to MPC of typical programs than it may appear at the first sight.  
%it is less clear how prevalent is wide branching.  That is, how niche is addressing the case of, say, $30$ or $100$ or $1000$-branch conditionals.  In this section, we argue that the ability to handle wide branching is beneficial to MPC of typical programs.

Our main observation is that free/cheap branching, such as what is achieved by our work, enables highly optimized handling of general flow control of programs. It is easiest to consider this by first considering an example.

Consider a program $P$ consisting of a loop $L_1$ followed with a loop $L_2$.  Assume the total upper bound on runtime (total number of loop iterations $T$) of $P$ is known, as is usual in MPC. F However, we must protect the number of iterations $T_1$ of $L_1$ and $T_2$ of $L_2$. Implementing such a program with standard Yao GC requires us to pay double of the cost achievable with stacked garbling: we must execute loop $L_1$ $T$ times followed by executing $L_2$ $T$ times.  At the same time, SGC can simply execute  $\stack(L_1, L_2)$ $T$ times, a circuit twice smaller.  This observation corresponds to the following slightly more generalized program transformation: The program 
\[{\tt loop_{T_1} \{ s_0 \} ; \ s_2;\ loop_{T_2} \{ s_1 \}} \]
can be rewritten as 
\[ {\tt loop_T\ \{\ switch  (cond):\{ s_0\ |\ s_1\ |\ s_1\ |\ \mathtt{no-op}\}\ \}}, \]
where ${\tt s_i}$ are straightline programs.
Let's take this a step further, and consider the following program $P$ still bounded by $T$ total iterations of the inner loops:
\[{\tt loop_{T_0}\ \{ loop_{T_1} \{ s_0 \};\ s_2;\  loop_{T_2} \{ s_1 \}\ \} }.\] 
This program can be still be rewritten as  
\[{\tt loop_{T} \{\ switch  (cond):\{ s_0\ |\ s_1\ |\ s_2\ |\ \mathtt{no-op}\}\ \}},\] 
saving up to a factor $2T_0\times$ when evaluated with stacked garbling. \vlad{Here I want to add $s_i$ at i-th iteration of outer loop, so that our stacked program will have to have many branches.}

We don't attempt to systematize the possible SGC-based optimizations of the generic flow control. One goal here is to illustrate that SGC is an essential tool that will enable this research, and the SGC performance with high branching factor is essential.





 




\subsection{Source of $O(b^2)$ Computation Cost of \HK Stacked Garbling }
\label{sec:bsquaredcost}

It is instructive to explain the source of quadratic SGC computation of \HK, to help explain our work.

At a high level, the fundamental idea of Stacked Garbling is that the evaluator \E
guesses which branch is taken (she in fact tries  all $b$
branches) and evaluates this guessed branch with the appropriately reconstructed material.  Of course, for security, the guess is unverifiable by \E. 
Still, when she guesses right, she indeed evaluates the taken branch and
computes valid GC output labels for that branch.
However, when she guesses wrong, she ends up evaluating the branch
with so-called garbage material (material that is a random-looking string, not
an encryption of circuit truth tables), and ends up computing
\emph{garbage output labels} (i.e., labels that are not the encryption
of $0$ or $1$, but are instead random-looking strings).
%
To proceed past the exit of the conditional and continue garbled evaluation, it is necessary to
`collect'  these garbage labels, i.e., obliviously  discard them in favor of the valid
labels.  (Of course, the final output labels of the conditional will be fresh,  so that they cannot be cross-referenced with those obtained in branch evaluation.)


\HK show how to collect this garbage without
interaction using a 
%.  The main idea is to require SGC Generator \G to construct 
multiplexer garbled gadget, constructed by the SGC Generator \G.  
Building the \HK multiplexer requires \G to {\em know all possible
garbage labels} the evaluator might obtain.  Once this is satisfied, it is easy to see how \G can produce a gadget (e.g., an appropriately wired set of garbled translation tables) eliminating garbage and propagating true values.


{\bf The Uncertainty of \G.}
It is possible for generator to acquire these garbage labels.  \HK achieve this by having \G  emulate the actions of the
evaluator \E on all non-taken branches.  To see how this can be done, let's consider \G's knowledge and uncertainty about the garbled evaluation.  There are three sources of \G's uncertainty:
\begin{itemize}
	\item True values of inputs of all branches.  This is the largest uncertainty (exponential number of possibilities in the number of inputs to the conditional), and the easiest to deal with.  \HK introduce a simple and elegant trick of the circuit simply setting to a fixed value, e.g., all zeros, all the inputs to the inactive branches.  This fully resolves this kind of uncertainty wrt \G.
	\item True index of the actually taken branch, which we denote by \truth.
	\item \E's guess of value of \truth, which we denote by \guess.
\end{itemize}

Thus, there are $b^2$ pairs of labels (including  $b(b-1)$ garbage sets of labels and $b$ valid sets of labels)  that the evaluator
could arrive at: one for each combination of (\truth,\guess), the  actually taken  and
the incorrectly guessed branches. \vlad{is this correct: we have $b$ valid sets of labels?  also call them sets or pairs? decide on notation here.}
%


To aquire all possible garbage labels (and hence build the multiplexer for garbage collection), the \HK generator assumes all-zero inputs for non-taken branches, and emulates ``in its head'' \E's evaluation under all possible (\truth,\guess) combinations.  
% must construct all $b(b-1)$ sets of garbage labels,
This requires \G evaluate GC (i.e. call \Ev) $b(b-1)$ times on garbage material.
This is the source of the $O(b^2)$ computation.



\input{intuition}


\subsection{Our Contributions}
