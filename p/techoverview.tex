
\section{Technical Overview of Our Approach}
\label{sec:techOverview}

\begin{figure*}[t]
  \centering
  \input{fig/seed-tree}
  \caption{%
    Suppose there are $8$ branches $\cir_0$ through $\cir_7$, and
    suppose \E guesses that $\cir_0$ is the taken branch.
    If the taken branch is in the subtree $\cir_4$ through $\cir_7$,
    \E will generate the same garbage material for the entire subtree,
    regardless of which branch is actually taken.
    By extension, $\cir_0$ can only be evaluated against $\log 8 = 3$ garbage
    material strings: one for each sibling subtree (sibling subtrees
    are bracketed). Hence $\cir_0$ has only three possible sets of
    garbage output labels.
  }\label{fig:seed-tree}
\end{figure*}

We now informally present our construction with sufficient detail to introduce
the most interesting technical challenges and solutions.

\subsection{$O(b\log b)$ Stacked Garbling}
\label{sec:techOverviewSG}

Our main contribution is the reduction of SGC computation
from $O(b^2)$ to $O(b \log b)$.  Our constants are also
low: together \G and \E make a total of $\frac{5}{2} b \log b + b$ calls to \Gb\
and $b\log b + b$ calls  to \Ev.

We continue the discussion from~\Cref{sec:intuition} in more detail.
Our main task is the garbage collection of output labels of {\em
incorrectly guessed} $(\truth, \guess)$ combinations 
%w.r.t. taken (active) branch, 
where
\guess is \E's guess of the active branch, and \truth defines the active branch w.r.t. \guess.
Wlog, let $b$ be a power of $2$ to simplify notation.
Consider a binary tree where the leaves are the $b$ branches
$\cir_0,...,\cir_{b-1}$.  The tree provides an infrastructure to group branches and to unify processing.


Fix one of $b$ choices for \guess.  In contrast with~\HK, which then considers $b$ choices for \truth independently from \guess, we define \truth\ {\em in relation} to \guess, and consider fewer \truth options.
Namely,
% for each tree level $i$, 
we  let \truth  denote the sibling subtree of \guess that contains the
active branch (cf. notation~\Cref{sec:intuition}). 
Given a fixed incorrect \guess, there are only $\log b$ choices for
\truth.\footnote{We focus on garbage collection and
consider only incorrect guesses;  managing output labels of the correctly guessed branches is straightforward and cheap.}
While we have redefined \truth, the active branch ID \aid\ continues
to point to the single active branch.
%
Our garbled gadgets compute functions of \aid.
% In contrast to \HK, where \truth\ and the active branch ID \aid\ are
% the same, our \truth\ is a subtree \emph{containing} \aid.

For concreteness,
%in our discussion we 
consider the illustrative example of an $8$-leaf tree in~\Cref{fig:seed-tree} where $\guess=0$. 
The discussion and arguments pertaining to this special case generalize to arbitrary $b$ and $\guess$.

Consider the four scenarios where one of the branches $\cir_4-\cir_7$ is active.
These four scenarios each correspond
to $\truth = 1$: $\cir_4-\cir_7$ all belong to the level-$1$ sibling subtree of
$\cir_0$.
%
We ensure that \E's unstacking and evaluation in each
of these four cases is \emph{identical}, and hence she evaluates the
same garbage output labels in these four cases.  More generally, we achieve identical processing for all leaves of each sibling subtree.
Let \aid\ denote the index of the active branch. That is, \aid\ is a $\log
b$-bit integer that points to the active branch.
% To achieve our objective, \E will use garbled labels corresponding to
% \aid to compute seeds for the various nodes in the tree.

% Recall, as part of GC  evaluation, \aid is computed by the circuit, and \E obtains the corresponding $ \log b$-long vector of GC labels $\vec S$, where
% $S[i] \in \{S^0[i],S^1[i]\}$; \G of course knows all labels $S^0[i],S^1[i]$.

\subsubsection{Actions and gadgets of \G.}

\begin{figure}[t!]\centering\framebox{%
\begin{minipage}{1.05\linewidth}
\begin{itemize}
  \item \textsc{Inputs:} \gadget takes as input the active branch id
    \aid\ and
    the number of branches $b$.
  \item \textsc{Outputs:}
    \gadget outputs a sequence of evaluator seeds that form a binary branching tree:
  \[
    \es_{0, b-1}, \es_{0, \frac{b-1}{2}}, \es_{\frac{b-1}{2}+1,b-1},
    \ldots, \es_0, \es_1,\ldots \es_{b-1}
  \]
    such
    that for each node \node:
   \[
   \es_\node =
   \begin{cases}
     s_\node,& \text{if $\node$ is a sibling root of $\aid$}\\
     s_\node',& \text{otherwise}
   \end{cases}
  \]
  where $s_\node'$ is a uniform string indistinguishable from
  $s_\node$.
\end{itemize}
\end{minipage}
}\caption{%
  The \gadgetlong functionality. \gadgetlong is
  responsible for conveying only the sibling root seeds of \aid\ to \E.
  For every other node, \E obtains a different, but indistinguishable,
  seed that, when garbled, generates garbage material.
  %
  \gadgetlong is easily implemented as a garbled circuit gadget (i.e.,
  built from garbled rows).
}\label{fig:sortinghat}
\end{figure}

In the context of the example in~\Cref{fig:seed-tree}, \G  garbles
branches  $\cir_0,...,\cir_7$ as follows.
Recall, the active branch ID \aid\ is available to \G\ in form of
garbled labels.
% Given the labels corresponding to the active branch ID \aid,
\G chooses a random
seed for the root of the tree (denoted $s_{0,7}$ for the $8$-leaf tree
in~\Cref{fig:seed-tree}), and uses it to pseudorandomly derive seeds
for each node of the tree.  This is done in the standard manner, e.g.,
the immediate children of a seed $s$ are the PRF evaluations on inputs
$0$ and $1$ with the key $s$.
\G uses each leaf seed $s_i$ to garble the corresponding branch $\cir_i$ and stacks all garbled branches $\mat=\bigoplus_i \gcir_i$.  
%
This material $\mat$ is the large string that \G\ ultimately sends
across the network to \E.
We note two facts about $\mat$ and about the active branch $\aid$.
\begin{enumerate}
  \item \textbf{Correctness}: if \E\ obtains the $\log b$ seeds of the
    sibling roots of
    $\aid$, then she can regarble all circuits $\gcir_{i\neq \act}$,
    unstack by XORing with \mat, and obtain $\gcir_\act$, allowing her to
    correctly evaluate $\cir_\act$.
  \item \textbf{Security}: \E\ must not obtain any correct seed
    corresponding to any ancestor of \aid. If she did, she would learn (by garbling) the
    encoding of wire labels which would allow her to decrypt all
    intermediate wire values in $\cir_\act$.
    %
    Instead, \E\ will obtain `garbage' seeds indistinguishable yet
    distinct from the correct seeds generated by \G.
\end{enumerate}

To facilitate secure garbled evaluation of the conditional and meet the requirements of these two facts, in addition to \mat,
\G  generates and sends to \E a small (linear in the
number of branches with small constants) garbled gadget
that we call \gadget.\footnote{%
  In J.K. Rowling's Harry Potter universe, the `sorting hat' is a
  magical object that assigns new students to different school houses
  based on personality.
  Our \gadget\ `sorts' nodes of trees into two categories based on
  \aid: those that
  are `good' (i.e., sibling roots of the active branch) and those that
  are `bad'.
}
\gadget aids \E in her secure reconstruction of branch material. 
Specifically, \gadget takes as input labels corresponding to \aid\ and
produces candidate seeds for each node in the tree.
For each node \node, \gadget constructs a correct (i.e. as generated by \G) seed $s_\node$
if and only if \node is a sibling root  of the leaf \aid.
\gadget can easily be implemented as a collection of garbled rows.
Importantly, since this is a fixed
gadget, when evaluated on a node \node that is not a sibling root of
\aid, \E will obtain a {\em single} predictable to \G\ fixed garbage
seed. 
% We need to ensure this garbage value is the same for every
% \aid. This is easy to do.  Details follow:

For example in~\Cref{fig:seed-tree}, if the active branch is $\aid=4$,
then applying \gadget\ to nodes $\node_{0,3}, \node_{6,7},
\node_{5}$ will reconstruct the correct seeds $s_{0,3}, s_{6,7}, s_{5}$.  Applying \gadget to other nodes
will construct fixed garbage seeds.
If the active branch were instead $\aid=3$, then \gadget
would reconstruct the correct seeds $s_{4,7}, s_{0,1}, s_{2}$.
Critically, the
garbage seeds reconstructed
in both cases, e.g. for node $\node_{4,5}$, are the same.


\subsubsection{Actions of \E.}

It is now intuitive how \E proceed with unstacking. 
She applies \gadget and obtains a tree of random-looking seeds; of $2b$
seeds, only $\log b$ seeds just off the path to \aid\ (corresponding
to \aid's sibling roots) are correct.  \E guesses \guess; assuming
\guess, she uses only the sibling seeds of \guess to derive all
$b-1$ leaf seeds not equal to \guess.  She then garbles the $b-1$
branches $\cir_i$ and unstacks the corresponding GCs $\gcir_i$.

Clearly, if $\guess=\aid$, \E\ derives the intended leaf seeds
$s_{i\neq\aid}$, unstacks the intended garbled circuits
$\gcir_{i\neq\aid}$, and obtains the correct GC $\gcir_\aid$.
%
Consider the case where \E\ guesses wrong. %Firstly, there is no security violation since she will never receive any additional valid seeds;
\E simply unstacks wrong branches garbled with the wrong seeds.
Since \E never receives any additional valid seeds,
there is no security loss.  We next see that the number of different
garbage labels we must collect is small, and further that they can be
collected efficiently.

\subsubsection{Computational cost accounting.} Let's now verify that
we indeed reduced the number of calls to \Gb\ and \Ev\ to $O(b \log
b)$.  This is easily done by first considering how many such calls are
made by \E.  Consider branch $\cir_i$.  It is garbled $\log b$ times,
once with a seed (ultimately) derived from each seed on the path to
the root.  Thus, total number of calls by \E to \Gb\ is $b \log b$ and
to \Ev\ is exactly $b$.  

To construct the garbage collecting multiplexer, \G must obtain all possible garbage labels.  We
demonstrate that the total cost to the generator is $b (\log b +
1)$ calls to \Gb\ and $b \log b$ calls to \Ev.
First, consider only \Gb\ and consider the number of ways \E\ can garble a specific circuit $\cir_i$. Clearly, this is exactly $\log b+1$.

Now, consider the number of calls needed to \Ev.  Recall that our
goal was to ensure that \E constructs the same garbage output labels
for a branch $\cir_i$ in each scenario where \aid\ is in some fixed
sibling subtree of $\cir_i$. Note that the logic of \gadget\ ensures
that \E obtains the same sibling root seeds in each of these
scenarios, and therefore she constructs the same garblings. Hence,
since there are $\log b$ sibling subtrees of $\cir_i$, $\cir_i$ has
only $\log b$ possible garbage output labels.
Thus, in order to emulate \E\ in all settings and obtain all possible
garbage output labels, \G\ must garble and evaluate each branch $\log b$ times.


\subsection{Technical difference between our and~\HK binary braching}
\label{sec:techOverviewDiff}

A careful reader familiar with~\HK may notice that they present two
versions of stacked garbling.
The first handles high branching factors by recursively \emph{nesting}
conditionals.
Nested conditionals can be viewed as a binary branching
tree.
This first approach is then discarded in favor of a second, more efficient vector approach.
Our work advocates binary branching and yet substantially improves
over~\HK's vectorized approach.
Why is our binary branching better?

The problem with~\HK's recursive construction
is that the evaluator \E recursively garbles the garbage collecting multiplexer for
nested sub-conditionals.
However, doing so leads to a recursive emulation whereby \E
emulates herself (and hence \G emulates himself as well).
This recursion leads to quadratic cost for both players.
The way out is to treat the multiplexer separately, and to opt not
to stack it.
If multiplexers are not stacked, then \E need not garble them, and
hence \E\ need never emulate herself.
On top of this, we reduce the number of ways that individual branches
can be garbled via our \gadget.

\subsubsection{A note on nested branches.}
Nesting branches may seem desirable. Indeed, nested branches with
complex sequencing of instructions emerge
naturally in many programs.
%
Our approach operates directly over vectors of circuits and treats
them as binary branching trees.
This may at first seem like a disadvantage, since at the
time the first nested branching decision is made, it may not yet be
possible to make \emph{all} branching decisions.
%
There are two natural ways \ourschemelong\ can be used in such
contexts:
%
\begin{enumerate}
  \item Although we advocate for vectorized branching,
    \ourschemelong\ does support nested evaluation.
    More precisely, \ourschemelong\ handles branches by passing them
    to another \emph{underlying
    garbling scheme}, and it is secure to instantiate this underlying
    scheme with \ourschemelong\ itself.
    Although this is secure and correct, we do not necessarily
    recommend it. Using \ourschemelong\ in this recursive manner
    yields quadratic computation overhead.
  \item Refactorings can be applied to ensure branches
    are vectorized. For example, consider the following refactoring:
    \begin{align*}
      &{ \tt if~(e_0)~\{~s_0 ;
      if~(e_1)~\{~s_1~\}~else~\{~s_2~\}~\}~else~\{~s_3 ; s_4~\}
    \longrightarrow}
    \\
      &~~{ \tt if~(e_0)~\{~s_0~\}~else~\{~s_3~\};
        switch (2e_0 + (1 \minus e_0)e_1)~\{~s1~\}~\mid~\{~s_2~\}~\mid~\{~s_4~\}
    }
    \end{align*}
    Where $s_i$ are programs, $e_i$ are predicates on program
    variables, and where $s_0, s_3$ do not modify variables in $e_0$.
    This refactoring has replaced a nested conditional by a sequence
    of two `vectorized' conditionals, and hence made the approach
    amenable to our efficient algorithms.
\end{enumerate}
%


\subsection{Memory Efficiency of \ourschemelong}
\label{sec:memoryEfficiency}

\vlad{TBD. explain why HK20 is bad and how we resolve}




\subsection{Stacked garbling with and without Random Oracles}
\label{sec:techOverviewRO}


% We eliminate the need for employing calls to RO in~\HK.   

\HK (and we)
focus only on branching and leave the handling of low level gates to
another \emph{underlying} garbling scheme, \underscheme.
\HK\ assumes nothing about \underscheme except that it satisfies the standard
\cite{CCS:BelHoaRog12} properties, as well as their {\em stackability} property.
Assuming only  these properties does not preclude \underscheme's
labels being related to each other, which presents problems in the
standard model. \HK handles the possible use of related keys by using
a RO to construct their garbled gadgets.

We introduce a stronger requirement on \underscheme, which we call {\em strong stackability}.  Informally, it additionally requires that {\em all} output labels of \underscheme used in key derivation look uniformly random.  We show that this is sufficient for security in the standard model.

Of course, RO-based security theorems and proofs also work (and we explicitly claim them), and our gadgets could be slightly optimized in a natural manner under this assumption.





