\section{The \ourschemelong\ Garbling Scheme}\label{sec:approach}
In this section, we formalize our construction, \ourschemelong.
Throughout this section, consider a conditional circuit with $b$
branches.
For simplicity, we ignore the number input and output wires.

We adopt the above simplification because branching factor is the most interesting
aspect of \ourschemelong. We emphasize that ignoring inputs/outputs
does not hide high costs.
% \ourschemelong scales linearly with the number of gates per branch.
While we scale with the product of the number of inputs and $b$ (and
respectively the product of number of outputs and $b$), the
constants are low.
See \Cref{sec:eval} for evidence of these low constants.
Thus, inputs/outputs are of secondary concern to the circuit size,
which is often far larger than the number of inputs/outputs.

Consider garbled circuits $\gcir_i$ corresponding to each branch
$\cir_i$. Let $\nmat$ be the size of the largest such garbling: $\nmat
= \max_i |\gcir_i|$.
Given branching factor $b$, \ourschemelong\ features:
\begin{itemize}
  \item $O(\nmat)$ communication complexity.
  \item $O(\nmat b \log b)$ time complexity.
  \item $O(\nmat \log b)$ space complexity.
\end{itemize}

In this section, we formalize our algorithms and give proofs of the above
complexities. We postpone proofs of correctness and security to
\Cref{sec:proof}.

\ourschemelong\ is formalized as a \emph{garbling
scheme}~\cite{CCS:BelHoaRog12}.
Garbling schemes abstract the details of GC such that protocols can be written generically.
That is, \ourschemelong is a modular collection of algorithms, not a
protocol.
Our formalization specifically uses the modified garbling scheme
framework of \HK, which separates the \emph{topology} of circuits
(i.e., the concrete circuit description) from circuit material
(i.e., the collections of encryptions needed to securely evaluate the
circuit), an important modification for SGC.

A garbling scheme is a tuple of five algorithms:
\[ (\gev, \gEv, \gGb, \gEn, \gDe) \]
%
\begin{itemize}
  \item \gev\ specifies circuit semantics. For typical approaches that
    consider only low-level gates, \gev\ is usually not formalized since its
    implementation is implicitly understood by the community. We explicate \gev\ to formalize
    conventions of conditional evaluation.
  \item \gEv\ specifies how \E\ securely evaluates the GC.
  \item \gGb\ specifies how \G\ garbles the GC.
  \item \gEn\ and \gDe\ specify the translation of cleartext values
    to/from GC labels. That is, \gEn\ specifies how player
    inputs translate to input labels and \gDe\ specifies how outputs
    labels translate to cleartext outputs.
\end{itemize}
%
Correct garbling schemes ensure that the garbled functions \gGb, \gEn,
\gEv, and \gDe\ achieve the semantics specified by \gev.

Before we present our garbling scheme \ourschemelong, we introduce the
formal syntax of the circuits it manipulates.
Because our focus is conditional branching, we assume the existence of
an \emph{underlying garbling scheme} \underscheme.
\underscheme\ is responsible for handling the collections of low level
gates (typically AND and XOR gates) that we refer to as \emph{netlists}.
In our implementation, we instantiate \underscheme\ with the efficient
half-gates scheme of~\cite{EC:ZahRosEva15}.
We do not specify the syntax of netlists, and entirely leave their
handling to \underscheme.
Our circuit syntax is defined inductively:
Let $\cir_0, \cir_1$ be two arbitrary circuits and $\vec \cir$ be an
arbitrary vector of circuits. The space of
circuits is defined as follows:
\[
  \cir ::= \netlist(\cdot)~|~%
  \conditional(\vec \cir)~|~%
  \sequential(\cir_0, \cir_1)
\]

That is, a circuit is either (1) a netlist, (2) a conditional dispatch
over a vector of circuits (our focus), or (3) a sequence of two
circuits.
Sequences of circuits are necessary to allow arbitrary
control flow.


\begin{figure}
  \begin{adjustwidth}{-0.1\textwidth}{-0.1\textwidth}
  \centering
  \begin{minipage}[t]{0.56\linewidth}
    \begin{align*}
      &\ourscheme.\gev(\cir, \cirinp):\\
      &~~\codecomment{What are the circuit semantics?}\\
      &~~\switch~\cir:\\
      &~~~~\ccase~\netlist(\cdot): \creturn~\underscheme.\gev(\cir, \cirinp)\\
      &~~~~\ccase~\sequential(\cir_0, \cir_1):
      \creturn~\ourscheme.\gev(\cir_1, \ourscheme.\gev(\cir_0,
      \cirinp))\\
      &~~~~\ccase~\conditional(\vec{\cir}):\\
      &~~~~~~\codecomment{split branch index from input}\\
      &~~~~~~\aid \gets \cirinp[0..\log |\vec \cir|]\\
      &~~~~~~\cirinp' \gets \cirinp[\log |\vec \cir|..]\\
      &~~~~~~\codecomment{Run the active branch.}\\
      &~~~~~~\creturn~\ourscheme.\gev(\vec{\cir}[\aid], \cirinp')\\
      \\
      &\ourscheme.\gEv(\cir,\mat,\gcirinp):\\
      &~~\codecomment{How does \E evaluate the GC?}\\
      &~~\switch(\cir):\\
      &~~~~\ccase~\netlist(\cdot): \creturn~\underscheme.\gEv(\cir,\mat,\gcirinp)\\
      &~~~~\ccase~\sequential(\cir_0, \cir_1): \\
      &~~~~~~\mat_0\mid\mat_{tr}\mid\mat_1 \gets \mat\\
      &~~~~~~\creturn~\ourscheme.\gEv(\cir_1, \mat_1, \evtranslate(\ourscheme.\gEv(\cir_0, \mat_0, \cirinp), \mat_{tr})\\
      &~~~~\ccase~\conditional(\vec \cir): \creturn~\evcond(\vec \cir,
      \mat, \gcirinp)\\
      \\
      &\ourscheme.\gEn(e,\cirinp):\\
      &~~\codecomment{How do inputs map to labels?}\\
      &~~\codecomment{This works for all projective schemes:}\\
      &~~\gcirinp \gets \emptystring\\
      &~~\cfor~i \in 0..n\minus 1:\\
      &~~~~(X^0, X^1) \gets e[i]\\
      &~~~~\cif~\cirinp[i] = 0:~\{~\gcirinp[i] \gets X^0~\}~\celse:~\{~\gcirinp[i] \gets X^1~\}\\
      &~~\creturn~\gcirinp
    \end{align*}
  \end{minipage}
  %
  \begin{minipage}[t]{0.40\linewidth}
    \begin{align*}
      &\ourscheme.\gGb(1^\kappa, \cir, S)\\
      &~~\codecomment{How does \G garble the GC?}\\
      &~~\codecomment{$S$ is an explicit seed.}\\
      &~~\switch~\cir:\\
      &~~~~\ccase~\netlist(\cdot):\\
      &~~~~~~\creturn~\underscheme.\gGb(1^\kappa,\cir,S)\\
      &~~~~\ccase~\sequential(\cir_0, \cir_1):\\
      &~~~~~~\codecomment{Derive seeds for two circuits.}\\
      &~~~~~~S_0 \gets F_S(0)\\
      &~~~~~~S_1 \gets F_S(1)\\
      &~~~~~~(\mat_0, e_0, d_0) \gets \ourscheme.\gGb(1^\kappa,\cir_0, S_0)\\
      &~~~~~~(\mat_1, e_1, d_1) \gets \ourscheme.\gGb(1^\kappa,\cir_1, S_1)\\
      &~~~~~~\codecomment{Labels out of $\cir_0$ must be \emph{translated}}\\
      &~~~~~~\codecomment{to labels into $\cir_1$.}\\
      &~~~~~~\mat_{tr} \gets \gbtranslate(d_0,e_1)\\
      &~~~~~~\mat \gets \mat_0\mid \mat_{tr}\mid \mat_1\\
      &~~~~~~\creturn~(\mat, e_0, d_1)\\
      &~~~~\ccase~\conditional(\vec \cir): \creturn~\gbcond(\vec \cir, S)\\
      \\
      &\ourscheme.\gDe(d, \gcirout):\\
      &~~\codecomment{How do labels map to outputs?}\\
      &~~\codecomment{This works for all projective schemes:}\\
      &~~\cirout \gets \lambda\\
      &~~\cfor~i \in 0.. m\minus 1:\\
      &~~~~(Y^0, Y^1) \gets d[i]\\
      &~~~~\cif~\gcirout[i] = Y^0:~\cirout[i] \gets 0\\
      &~~~~\celse~\cif~\gcirout[i] = Y^1:~\cirout[i] \gets 1\\
      &~~~~\celse:~\mathtt{ABORT}\\
      &~~\creturn~\cirout
      % &\genprojection(n, S):\\
      % &~~p \gets \lambda\\
      % &~~\cfor~i \in 0..n\minus 1:\\
      % &~~~~X^0 \drawnfrom{S} \{0, 1\}^{\kappa}\\
      % &~~~~X^1 \drawnfrom{S} \{0, 1\}^{\kappa}\\
      % &~~~~c \drawnfrom{S} \{0, 1\}\\
      % &~~~~p \gets p \mid ((X^0\mid c), (X^1\mid \xor{1}{c}))\\
      % &~~\creturn~p
    \end{align*}
  \end{minipage}
  \end{adjustwidth}
  \caption{%
    Our garbling scheme \ourschemelong.
    The included algorithms are typical except for the handling of
    conditionals.
    \gEv\ and \gGb\ delegate the core of our approach to
    the delegation to
    \evcond\ and \gbcond\ respectively.
  }\label{fig:scheme}
\end{figure}


With our syntax established, we are ready to present our algorithms.
\begin{construction}[\ourschemelong]\label{ourconstr}
  \ourschemelong\ is the tuple of algorithms:
  \[ (\ourscheme.\gev, \ourscheme.\gEv, \ourscheme.\gGb, \ourscheme.\gEn, \ourscheme.\gDe) \]
  Definitions for each algorithm are listed in \Cref{fig:scheme}.
\end{construction}

\vlad{all properties are undefined.  Should we postpone theorem 1?  Or just add a forward pointer?}
Theorems and lemmas that follow imply the following core theorems:
\begin{theorem}
  Let $\underscheme$ be a garbling scheme that is
      \textbf{correct}, \textbf{strongly stackable},
      \textbf{authentic}, and \textbf{private}.
  Then \Cref{ourconstr} instantiated with $\underscheme$ is
      \textbf{correct}, \textbf{strongly stackable},
      \textbf{authentic}, and \textbf{private}.
\end{theorem}

\begin{theorem}
  Let $\underscheme$ be a garbling scheme satisfying the following
  property:
  \begin{itemize}
    \item Let $\cir$ be an arbitrary circuit and let $s$ be the size of
      material generated invoking $\underscheme.\gGb$ on $\cir$.
      Let both $\underscheme.\gEv$ and $\underscheme.\gGb$, invoked
      on $\cir$, run in $O(s)$ time and $O(s)$ space.
  \end{itemize}
  Then \Cref{ourconstr} instantiated with $\underscheme$ satisfies the
  following property.
  \begin{itemize}
    \item Let $\vec{\cir}$ be  vector of $b$ arbitrary circuits. Let $\nmat$ be
      the maximum size of the garblings constructed by calling
      $\underscheme.\gGb$ on each of these $b$ circuits.
      Then both $\ourscheme.\gEv$ and $\ourscheme.\gGb$, invoked on
      $\conditional(\vec{\cir})$, run in
      $O(\nmat b \log b)$ time and $O(\nmat \log b$) space.
  \end{itemize}
\end{theorem}

We draw attention to two key details of these algorithms:
(1) $\ourscheme.\gEv$ delegates to a subprocedure \evcond\ and (2)
$\ourscheme.\gGb$ delegates to a subprocedure \gbcond.
%
All details of conditionals are handled by these two subprocedures.
%
Aside from these delegations, the algorithms in \Cref{fig:scheme} are
relatively unsurprising:
the algorithms closely match \HK's construction and essentially
provide 
%nothing more than 
infrastructure needed to host our contribution.
%
We briefly discuss most relevant details of these 
%less interesting 
algorithms before returning
to an extended discussion of \evcond\ and \gbcond~(c.f. \Cref{sec:approach-cond}):

\begin{itemize}
  \item \textbf{Projectivity.} \ourschemelong\
    is a \emph{projective garbling scheme}~\cite{CCS:BelHoaRog12}.
    This stronger definition requires that the input \emph{encoding string}
    $e$ and output \emph{decoding string} $d$ have a specific format:
    they must both be a vector of pairs of labels such that the left
    element of each pair is a label encoding logical $0$ and the right
    element of each pair is a label encoding logical $1$.
    Thus, $\ourscheme.\gEn$ and $\ourscheme.\gDe$ are straightforward
    mappings between cleartext values and encoding/decoding strings.
  \item \textbf{Delegation to \underscheme.} Note that
    $\ourscheme.\gev$, $\ourscheme.\gEv$, and $\ourscheme.\gDe$ indeed
    directly delegate to \underscheme\ in the case of a netlist.
  \item \textbf{Sequences and Translation.} In a sequence of two
    circuits, all output wires of the first circuit are passed as the inputs
    to the second. Because these two circuits are garbled starting
    from different seeds, the output labels from $\cir_0$ will not match the required
    input encoding of $\cir_1$.
    %
    We thus implement a \emph{translation} component ($\evtranslate$
    and $\gbtranslate$) that implements via garbled rows
    straightforward translation from one encoding to another.
    \dave{Add note about standard model and PRF to implement
    translation}
\end{itemize}

\subsection{Algorithms for Handling of Conditionals}\label{sec:approach-cond}

With the remaining formalization out of the way, we focus specifically
on conditional branching. Our specific goal is to formalize \evcond\
and \gbcond, the key sub-procedures invoked by $\ourscheme.\gEv$ and
$\ourscheme.\gGb$ respectively.
Note, our presentation is a formalization of the discussion in
\Cref{sec:techOverview}; the following explores the technical aspects
of our construction, but the reader should refer to
\Cref{sec:techOverview} for unifying high level intuition.

\subsubsection{Garbling Subtrees.}
\begin{figure}
  \begin{align*}
    &\gbtree(\vec{\cir}, i, j, seed):\\
    &~~\cif~i = j:\\
    &~~~~\codecomment{Base case of $1$ branch.}\\
    &~~~~M, e, \cdot \gets \gb(\vec\cir[i], seed)\\
    &~~~~\creturn~M, e\\
    &~~\celse:\\
    &~~~~\codecomment{Expand child seeds using PRF.}\\
    &~~~~seed_L \gets F_{seed}(0)\\
    &~~~~seed_R \gets F_{seed}(1)\\
    &~~~~\codecomment{Recursively garble both child trees and stack
    material.}\\
    &~~~~k \gets \halfway(i, j)\\
    &~~~~M_L, e_L \gets \gbtree(\vec{\cir}, i, k, seed_L)\\
    &~~~~M_R, e_R \gets \gbtree(\vec{\cir}, k + 1, j, seed_R)\\
    &~~~~\creturn~(M_L \oplus M_R, e_L \mid e_R)\\
    \\
    &\halfway(i, j):\\
    &~~\codecomment{Simple helper for splitting range of branches (approximately) in half.}\\
    &~~\creturn~i+\left\lfloor \frac{j-i}{2} \right\rfloor\\
  \end{align*}
  \caption{%
    The helper algorithm \gbtree\ starts from a single seed
    at the root of a subtree $\node_{i,j}$, derives all seeds in the
    subtree, garbles all branches in the subtree, and stacks (using
    XOR) all resultant material. The procedure also returns the input
    encodings for all branches.
  }\label{fig:gbtree}
\end{figure}

Recall, we organize the $b$ branches into a binary branching tree.
% Both \evcond\ and \gbcond\ frequently perform a common task:
% they garble all branches in an entire subtree and stack together all
% material.
For \emph{each} internal node of the tree, both \evcond\ and \gbcond\
perform a common task: they garble all branches in the entire subtree
rooted at that node and stack together all material.
%
We thus start by definining a procedure, \gbtree~(\Cref{fig:gbtree}),
which specifically performs this basic task.

Specifically, \gbtree\ recursively descends through the
subtree starting from its root, uses a PRF to derive child seeds from the parent seed, and at the
leaves garbles the branches.
As the recursion propagates back up the tree, the procedure stacks the
garblings together.
%
The recursion tracks two integers $i$ and
$j$, denoting the range of branches $\cir_i..\cir_j$ that are to
be stacked together.
\evcond\ and \gbcond\ use a similar strategy, and all three algorithms
maintain an invariant that $i,j$ refers to a valid node $\node_{i,j}$ in the binary
branching tree over the $b$ branches (c.f. \Cref{fig:gbtree} for an
example).
%
Note that because \evcond\ and \gbcond\ invoke \gbtree\ at
\emph{every} node, this entails that both procedures garble
each branch $\cir_i$ more than once, but with different seeds.
As discussed in \Cref{sec:techOverview}, this repeated garbling is key
to reducing the total number of possible garbage outputs.


We note two performance properties of \gbtree, recalling that we ignore
the number of inputs/outputs and consider branches with maximum
garbling size $\nmat$.
\begin{lemma}\label{lemma:gbtreetime}
  Let $\vec{\cir}$ be a vector of $b$ circuits,
  let $i, j \in \{0, b-1\}$ satisfy $i \leq j$,
  and let $seed \in \{0, 1\}^\kappa$ be an arbitrary string.
  Then $\gbtree(\vec \cir, i, j, seed)$ invokes $\gGb$ $j - i + 1$ times.
\end{lemma}
\begin{proof}
  Immediate. The procedure only invokes $\gGb$ at the base case.
\end{proof}
In other words, the algorithm garbles each branch only once.
Note that while \Cref{lemma:gbtreetime} (and also
\Cref{lemma:gbtreespace}) holds for all $i, j$ we are
only concerned with it holding for $i, j$ that represent valid nodes
in the binary branching tree of circuits.


\begin{lemma}\label{lemma:gbtreespace}
  Let $\vec{\cir}$ be an arbitrary vector of $b$ circuits,
  let $i, j \in \{0, b-1\}$ satisfy $i \leq j$,
  and let $seed \in \{0, 1\}^\kappa$ be a arbitrary string.
  If $\Gb$ runs in $O(\nmat)$ space,
  then $\gbtree(\vec \cir, i, j, seed)$ runs in $O(\nmat \log (j-i+1))$ space.
\end{lemma}
\begin{proof}
  In the base case, $\gbtree$ invokes $\gb$. By assumption, this runs
  within our space requirement, and generates a garbling of maximum
  size $\nmat$.
  %
  In the general case, $\gbtree$ recursively invokes itself twice.
  Thus, after the first call has finished, we must store the
  intermediate result $M_L$.
  %
  Thus, at each recursive call site, we store a string of size
  $O(\nmat)$.
  Because each recursive call divides the range of considered circuits
  in half, the recursive tree has depth $O(\log(j-i+1))$.
  Hence, the total required storage is $O(\nmat \log(j-i+1))$.
\end{proof}

\subsubsection{Gadgets}
TODO

\subsubsection{Evaluating Conditionals}

\begin{figure}
  \begin{align*}
    &\evcond(\vec{\cir}, \mat, X):\\
    &~~b \gets | \vec{\cir} |\\
    &~~\codecomment{Parse the active branch index from the rest of the
    input.}\\
    &~~\aid \mid X' \gets X\\
    &~~\codecomment{Parse material for gadgets and body of conditional.}\\
    &~~\mat_\gadget \mid \mat_{dem} \mid \mat_{cond} \mid \mat_{mux} \gets \mat\\
    &~~\codecomment{Run $\gadget$ to compute all of \E's seeds.}\\
    &~~es \gets \gadget.\mathtt{Ev}(\aid, \mat_\gadget)\\
    &~~\codecomment{Run the demultiplexer to compute input for each
    branch $\cir_i$.}\\
    &~~\vec{X}_{cond} \gets \evdem(\aid, X, \mat_{dem})\\
    \\
    &~~\codecomment{We define a recursive subprocedure that evaluates $\cir_i - \cir_j$ using material $\mat$.}\\
    &~~\evcond'(i, j, \mat_{i, j}):\\
    &~~~~\cif~i = j:\\
    &~~~~~~\codecomment{Base case: compute output by evaluating the branch normally.}\\
    &~~~~~~\codecomment{This base case corresponds to $\guess = i$.}\\
    &~~~~~~\codecomment{Accumulate output labels into the vector
    $\gcirout_{cond}$ (for later garbage collection).}\\
    &~~~~~~\gcirout_{cond}[i] \gets \ev(\cir_i, M, \gcirinp_{cond}[i])\\
    &~~~~\celse:\\
    &~~~~~~k \gets \halfway(i, j)\\
    &~~~~~~\codecomment{Garble the right subtree using the available
    seed,}\\
    &~~~~~~\codecomment{unstack, and recursively evaluate the left
    subtree.}\\
    &~~~~~~\mat_{k+1,j}, \cdot \gets \gbtree(\vec{\cir}, k+1, j, es_{k+1, j})\\
    &~~~~~~\evcond'(i, k, \mat_{i, j} \oplus \mat_{k+1,j})\\
    &~~~~~~\codecomment{Symmetrically evaluate the right subtree.}\\
    &~~~~~~\mat_{i, k}, \cdot \gets \gbtree(\vec{\cir}, i, k, es_{i,k})\\
    &~~~~~~\evcond'(k+1, j, \mat_{i, j} \oplus \mat_{i, k})\\
    \\
    &~~\codecomment{Start recursive process from the top of the tree.}\\
    &~~\evcond'(0, b-1, M_{cond})\\
    &~~\codecomment{Eliminate garbage and propagate $\vec{Y}_\aid$ via
    the multiplexer.}\\
    &~~\creturn~\evmux(\aid, \vec{Y}_{cond}, M_{mux})
  \end{align*}
  \caption{%
    \E's procedure, \evcond, for evaluating a conditional with $b$ branches.
    \evcond\ evaluates each branch; $b-1$ evaluations
    result in garbage outputs and one (the evaluation of
    $\cir_\aid$) results in valid outputs.
    The multiplexer collects garbage and propagates output from
    $\cir_\aid$.
    \evcond\ involves $b \log b$ calls to \gGb (via \gbtree), and each
    branch evaluation is done with respect to the garbling of that
    branch's sibling subtrees.
  }
\end{figure}

TODO explain \evcond.


Next, we examine the efficiency properties of \evcond.

In terms of time complexity, we start by examining the \emph{concrete}
efficiency on conditionals with $2^k$ branches for some $k$.
%
Of course, the following proof generalizes to a asymptotic efficiency
regardless of the number of branches, but we include the concrete
proof to emphasize the low constants involved.

\begin{lemma}\label{lemma:evcondtime}
  Let $b = 2^k$ for some $k \in \mathbb{N}$.
  Let $\vec{\cir}$ be a vector of $b$ branches, $\mat$ be a string of
  length $\nmat$, and $\gcirinp$ be a vector of labels of length
  $\inpsize(\conditional(\vec{\cir}))$.
  $\evcond(\vec{\cir}, \mat, \gcirinp)$ calls \gGb\ $b \log b$ times
  and calls \gEv\ $b$ times.
\end{lemma}
\begin{proof}
  First, it is trivial that \gEv\ is called $b$ times: the
  procedure is called only at the base case, which is reached once per
  branch.

  Second, \gbtree\ is called twice in the general case, each on a
  subtree of half of the current branches.
  %
  For example, at the root \gbtree\ is called on every branch, which, by
  \Cref{lemma:gbtreetime}, implies $b$ calls to \Gb.
  Now consider a binary branching tree whose leaves are the $b$
  branches and whose internal nodes each correspond to
  a recursive invocation of $\evcond'$.
  At every level of the tree, each internal node garbles every
  leaf below it, via \gbtree.
  Hence, every level of the tree entails $b$ calls to \Gb.
  Since the binary branching tree has $\log b$ levels, there are $b
  \log b$ total calls to \Gb.
\end{proof}

By essentially exactly the same argument, one can prove the following
lemma for arbitrary numbers of branches:
\begin{lemma}\label{lemma:evcondtime-general}
  Let $\vec{\cir}$ be a vector of $b$ circuits, $\mat$ be a string of
  length $\nmat$, and $\gcirinp$ be a vector of labels of length
  $\inpsize(\conditional(\vec{\cir}))$.
  $\evcond(\vec{\cir}, \mat, \gcirinp)$ calls \gGb\ $O(b \log b)$ times
  and calls \gEv\ $b$ times.
\end{lemma}

\begin{lemma}\label{lemma:evcondspace}
  Let $\vec{\cir}$ be a vector of $b$ circuits, $\mat$ be a string of
  length $\nmat$, and $\gcirinp$ be a vector of labels of length
  $\inpsize(\conditional(\vec{\cir}))$.
  $\evcond(\vec{\cir}, \mat, \gcirinp)$ runs in $O(\nmat \log b)$ space.
\end{lemma}
\begin{proof}
  Trivial, since no material is stored at recursive call sites.
  Thus the space complexity is inherited from
  \gbtree~(\Cref{lemma:gbtreespace}).
\end{proof}

\subsubsection{Garbling Conditionals}

\begin{lemma}\label{lemma:gbcondtime}
\end{lemma}
\begin{proof}
\end{proof}

\begin{lemma}\label{lemma:gbcondspace}
\end{lemma}
\begin{proof}
\end{proof}

\begin{figure}
  \begin{align*}
    &\gbcond(\vec{\cir}, S):\\
    &~~b \gets | \vec{\cir} |\\
    &~~\codecomment{Recursively derive all `good' seeds for the entire tree.}\\
    &~~s \gets \mathtt{DeriveSeedTree}(S, b)\\
    &~~\codecomment{Sample an input encoding for the conditional.}\\
    &~~e \gets \genprojection(S, n)\\
    &~~\codecomment{Parse encoding into encoding of active branch
    index and encoding of rest of input.}\\
    &~~e_\aid\mid e' \gets e\\
    &~~\codecomment{Garble \gadget\ based on the encoding of \aid.}\\
    &~~\codecomment{This outputs material as well as the tree of all
    `bad' seeds $s'$.}\\
    &~~\mat_\gadget, s' \gets \gadget.\mathtt{Gb}(e_\aid, s)\\
    &~~\codecomment{Construct the stacked material and input encodings for each branch.}\\
    &~~M_{cond}, e_{cond} \gets \gbtree(\vec{\cir}, 0, b-1, s_{0, b-1})\\
    &~~\codecomment{The demux conditionally translates the input encoding $e'$}\\ 
    &~~\codecomment{to one of the branch encodings in $e_{cond}$ based on $e_\aid$.}\\
    &~~\mat_{dem}, \Lambda_{in} \gets \gbdem(e_\aid, e', e_{cond})\\
    &~~\codecomment{Compute all possible garbage outputs.}\\
    &~~\Lambda_{out} \gets \computegarbage(\vec{\cir}, M_{cond}, \Lambda_{in}, s, s')\\
    &~~\codecomment{The demultiplexer collects garbage outputs.}\\
    &~~\mat_{mux} \gets \gbmux(e_\aid, d, \vec{d}, \Lambda_{out})\\
    &~~\creturn~(\mat_\gadget \mid \mat_{dem} \mid \mat_{cond} \mid \mat_{mux}, e, d)
  \end{align*}
  \caption{%
    The algorithm for garbling a conditional vector.
    Given $b$ branches, \gbcond\ returns (1) the stacked material, (2)
    the input encoding string, (3) all $b$ output decoding strings,
    and (4) all $b\log b$ possible garbage output label vectors.
  }
\end{figure}

\begin{figure}
  \begin{align*}
    &\computegarbage(\vec{\cir}, \mat, \Lambda_{in}, s, s'):\\
    &~~\codecomment{We first define a recursive subprocedure.}\\
    &~~\computegarbage'(i, j, \mat_{i,j}, \vec{\mat}'):\\
    &~~~~\codecomment{Compute all possible garbage outputs from
    branches $\cir_i-\cir_j$.}\\
    &~~~~\codecomment{$\vec{\mat}'$ is a vector of the bad garblings of
      all sibling roots of the current node.}\\
    &~~~~\cif~i = j:\\
    &~~~~~~\codecomment{Base case: loop over all possible garbage material}\\
    &~~~~~~\codecomment{and accumulate garbage outputs into
    $\Lambda_{out}$.}\\
    &~~~~~~acc \gets \mat_{i,i}\\
    &~~~~~~\cfor~k \in 0..|\log b|:\\
    &~~~~~~~~\codecomment{Emulate all possible bad evaluations of $\cir_i$.}\\
    &~~~~~~~~acc \gets acc \oplus \vec{\mat}'[k]\\
    &~~~~~~~~\Lambda_{out}[i][k] \gets \gEv(\vec{\cir}[i], acc, \Lambda_{in}[k])\\
    &~~~~\celse:\\
    &~~~~~~k \gets \halfway(i, j)\\
    &~~~~~~\codecomment{Compute the good material for both subtrees.}\\
    &~~~~~~\mat_{i, k}, \cdot \gets \gbtree(\vec{\cir}, i, k, s_{i, k})\\
    &~~~~~~\mat_{k+1, j} \gets \mat_{i, j} \oplus \mat_{i, k}\\
    &~~~~~~\codecomment{Compute the bad material for both subtrees.}\\
    &~~~~~~\mat_{i, k}' \gets \gbtree(\vec{\cir}, i, k, s'_{i, k})\\
    &~~~~~~\mat_{k+1, j}' \gets \gbtree(\vec{\cir}, k+1, j, s'_{k+1, j})\\
    &~~~~~~\codecomment{Recursively compute all garbage outputs.}\\
    &~~~~~~\computegarbage'(i, k, (\mat_{k+1,j} \oplus \mat_{k+1,j}') \mid \vec{\mat}')\\
    &~~~~~~\computegarbage'(k+1, j, (\mat_{i,k} \oplus \mat_{i,k}') \mid \vec{\mat}')\\
    \\
    &~~b \gets |\vec{\cir}|\\
    &~~\codecomment{Start the recursive process using the top level material $\mat$}\\
    &~~\codecomment{and using the empty vector of bad sibling material.}\\
    &~~\computegarbage'(0, b-1, \mat, [~])\\
    &~~\creturn~\Lambda_{out}
  \end{align*}
  \caption{%
    \computegarbage\ allows \G\ to compute the possible garbage output labels
    from evaluation of inactive branches.
    Specifically, the algorithm takes as arguments (1) the vector of
    conditional branches $\vec{\cir}$, (2) the `good' material for the
    conditional $M$, (3) the garbage input labels $\Lambda_{in}$, (4)
    the tree of `good' seeds (i.e. the seeds used by \G\ to generate
    $M$) $s$, and (5) the tree of `bad' seeds $s'$.
    The algorithm outputs $\Lambda_{out}$, the vector (length $b$) of
    vectors (each length $\log b$) of output labels from each
    branch.
  }
\end{figure}
