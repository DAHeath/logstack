\section{The \ourschemelong\ Garbling Scheme}\label{sec:approach}
In this section, we formalize our construction, \ourschemelong.
Throughout this section, consider a conditional circuit with $b$
branches.
For simplicity, we ignore the number input and output wires.

We adopt the above simplification because branching factor is the most interesting
aspect of \ourschemelong. We emphasize that ignoring inputs/outputs
does not hide high costs.
% \ourschemelong scales linearly with the number of gates per branch.
While we scale with the product of the number of inputs and $b$ (and
respectively the product of number of outputs and $b$), the
constants are low (see \Cref{sec:eval} for evidence).
Thus, inputs/outputs are of secondary concern to the circuit size,
which is often far larger than the number of inputs/outputs.

Consider garbled circuits $\gcir_i$ corresponding to each branch
$\cir_i$. Let $\nmat$ be the size of the largest such garbling: $\nmat
= \max_i |\gcir_i|$.
Given branching factor $b$, \ourschemelong\ features:
\begin{itemize}
  \item $O(\nmat)$ communication complexity.
  \item $O(\nmat b \log b)$ time complexity.
  \item $O(\nmat \log b)$ space complexity.
\end{itemize}

% In this section, we formalize our algorithms and give proofs of the above
% complexities. We postpone proofs of correctness and security to
% \Cref{sec:proof}.

\ourschemelong\ is formalized as a \emph{garbling
scheme}~\cite{CCS:BelHoaRog12}.
Garbling schemes abstract the details of GC such that protocols can be written generically.
That is, \ourschemelong is a modular collection of algorithms, not a
protocol.
Our formalization specifically uses the modified garbling scheme
framework of \HK, which separates the \emph{topology} of circuits
(i.e., the concrete circuit description) from circuit material
(i.e., the collections of encryptions needed to securely evaluate the
circuit), an important modification for SGC.

A garbling scheme is a tuple of five algorithms:
\[ (\gev, \gEv, \gGb, \gEn, \gDe) \]
%
\begin{itemize}
  \item \gev\ specifies circuit semantics. For typical approaches that
    consider only low-level gates, \gev\ is often left implicit since its
    implementation is generally understood. We explicate \gev\ to formalize
    conventions of conditional evaluation.
  \item \gEv\ specifies how \E\ securely evaluates the GC.
  \item \gGb\ specifies how \G\ garbles the GC.
  \item \gEn\ and \gDe\ specify the translation of cleartext values
    to/from GC labels. That is, \gEn\ specifies how player
    inputs translate to input labels and \gDe\ specifies how outputs
    labels translate to cleartext outputs.
\end{itemize}
%
Correct garbling schemes ensure that the garbled functions \gGb, \gEn,
\gEv, and \gDe\ achieve the semantics specified by \gev.

Before we present our garbling scheme \ourschemelong, we introduce the
formal syntax of the circuits it manipulates.
Because our focus is conditional branching, we assume
an \emph{underlying garbling scheme} \underscheme.
\underscheme\ is responsible for handling the collections of low level
gates (typically AND and XOR gates) that we refer to as \emph{netlists}.
In our implementation, we instantiate \underscheme\ with the efficient
half-gates scheme of~\cite{EC:ZahRosEva15}.
We do not specify the syntax of netlists, and entirely leave their
handling to \underscheme.
Our circuit syntax is defined inductively:
Let $\cir_0, \cir_1$ be two arbitrary circuits and $\vec \cir$ be a
a vector of arbitrary circuits. The space of
circuits is defined as follows:
\[
  \cir ::= \netlist(\cdot)~|~%
  \conditional(\vec \cir)~|~%
  \sequential(\cir_0, \cir_1)
\]

That is, a circuit is either (1) a netlist, (2) a conditional dispatch
over a vector of circuits (our focus), or (3) a sequence of two
circuits.
Sequences of circuits are necessary to allow arbitrary
control flow.


\begin{figure}
  \begin{adjustwidth}{-0.1\textwidth}{-0.1\textwidth}
  \centering
  \begin{minipage}[t]{0.56\linewidth}
    \begin{align*}
      &\ourscheme.\gev(\cir, \cirinp):\\
      &~~\codecomment{What are the circuit semantics?}\\
      &~~\switch~\cir:\\
      &~~~~\ccase~\netlist(\cdot): \creturn~\underscheme.\gev(\cir, \cirinp)\\
      &~~~~\ccase~\sequential(\cir_0, \cir_1):
      \creturn~\ourscheme.\gev(\cir_1, \ourscheme.\gev(\cir_0,
      \cirinp))\\
      &~~~~\ccase~\conditional(\vec{\cir}):\\
      &~~~~~~\codecomment{split branch index from input}\\
      &~~~~~~\aid\mid\cirinp' \gets \cirinp\\
      &~~~~~~\codecomment{Run the active branch.}\\
      &~~~~~~\creturn~\ourscheme.\gev(\vec{\cir}[\aid], \cirinp')\\
      \\
      &\ourscheme.\gEv(\cir,\mat,\gcirinp):\\
      &~~\codecomment{How does \E evaluate the GC?}\\
      &~~\switch(\cir):\\
      &~~~~\ccase~\netlist(\cdot): \creturn~\underscheme.\gEv(\cir,\mat,\gcirinp)\\
      &~~~~\ccase~\sequential(\cir_0, \cir_1): \\
      &~~~~~~\mat_0\mid\mat_{tr}\mid\mat_1 \gets \mat\\
      &~~~~~~\creturn~\ourscheme.\gEv(\cir_1, \mat_1,
      \evtranslate(\ourscheme.\gEv(\cir_0, \mat_0, \gcirinp), \mat_{tr})\\
      &~~~~\ccase~\conditional(\vec \cir): \creturn~\evcond(\vec \cir,
      \mat, \gcirinp)\\
      \\
      &\ourscheme.\gEn(e,\cirinp):\\
      &~~\codecomment{How do inputs map to labels?}\\
      &~~\codecomment{This works for all projective schemes:}\\
      &~~\gcirinp \gets \emptystring\\
      &~~\cfor~i \in 0..\inpsize(\cir)\minus 1:\\
      &~~~~(X^0, X^1) \gets e[i]\\
      &~~~~\cif~\cirinp[i] = 0:~\{~\gcirinp[i] \gets X^0~\}~\celse:~\{~\gcirinp[i] \gets X^1~\}\\
      &~~\creturn~\gcirinp
    \end{align*}
  \end{minipage}
  %
  \begin{minipage}[t]{0.40\linewidth}
    \begin{align*}
      &\ourscheme.\gGb(1^\kappa, \cir, S)\\
      &~~\codecomment{How does \G garble the GC?}\\
      &~~\codecomment{$S$ is an explicit seed.}\\
      &~~\switch~\cir:\\
      &~~~~\ccase~\netlist(\cdot):\\
      &~~~~~~\creturn~\underscheme.\gGb(1^\kappa,\cir,S)\\
      &~~~~\ccase~\sequential(\cir_0, \cir_1):\\
      &~~~~~~\codecomment{Derive seeds for two circuits.}\\
      &~~~~~~S_0 \gets F_S(0)\\
      &~~~~~~S_1 \gets F_S(1)\\
      &~~~~~~(\mat_0, e_0, d_0) \gets \ourscheme.\gGb(1^\kappa,\cir_0, S_0)\\
      &~~~~~~(\mat_1, e_1, d_1) \gets \ourscheme.\gGb(1^\kappa,\cir_1, S_1)\\
      &~~~~~~\codecomment{Labels out of $\cir_0$ must be \emph{translated}}\\
      &~~~~~~\codecomment{to labels into $\cir_1$.}\\
      &~~~~~~\mat_{tr} \gets \gbtranslate(d_0,e_1)\\
      &~~~~~~\mat \gets \mat_0\mid \mat_{tr}\mid \mat_1\\
      &~~~~~~\creturn~(\mat, e_0, d_1)\\
      &~~~~\ccase~\conditional(\vec \cir): \creturn~\gbcond(\vec \cir, S)\\
      \\
      &\ourscheme.\gDe(d, \gcirout):\\
      &~~\codecomment{How do labels map to outputs?}\\
      &~~\codecomment{This works for all projective schemes:}\\
      &~~\cirout \gets \lambda\\
      &~~\cfor~i \in 0.. \outsize(\cir)\minus 1:\\
      &~~~~(Y^0, Y^1) \gets d[i]\\
      &~~~~\cif~\gcirout[i] = Y^0:~\cirout[i] \gets 0\\
      &~~~~\celse~\cif~\gcirout[i] = Y^1:~\cirout[i] \gets 1\\
      &~~~~\celse:~\mathtt{ABORT}\\
      &~~\creturn~\cirout
      % &\genprojection(n, S):\\
      % &~~p \gets \lambda\\
      % &~~\cfor~i \in 0..n\minus 1:\\
      % &~~~~X^0 \drawnfrom{S} \{0, 1\}^{\kappa}\\
      % &~~~~X^1 \drawnfrom{S} \{0, 1\}^{\kappa}\\
      % &~~~~c \drawnfrom{S} \{0, 1\}\\
      % &~~~~p \gets p \mid ((X^0\mid c), (X^1\mid \xor{1}{c}))\\
      % &~~\creturn~p
    \end{align*}
  \end{minipage}
  \end{adjustwidth}
  \caption{%
    Our garbling scheme \ourschemelong.
    The included algorithms are typical except for the handling of
    conditionals.
    \gEv\ and \gGb\ delegate the core of our approach: \evcond\
    (\Cref{fig:evcond}) and
    \gbcond\ (\Cref{fig:gbcond}).
  }\label{fig:scheme}
\end{figure}


With our syntax established, we are ready to present our algorithms.
\begin{construction}[\ourschemelong]\label{ourconstr}
  \ourschemelong\ is the tuple of algorithms:
  \[ (\ourscheme.\gev, \ourscheme.\gEv, \ourscheme.\gGb, \ourscheme.\gEn, \ourscheme.\gDe) \]
  Definitions for each algorithm are listed in \Cref{fig:scheme}.
\end{construction}

We discuss correctness and security of \Cref{ourconstr} in
\Cref{sec:proof}.
\iffull
Due to lack of space, proofs of these properties are
in Supplementary Material.
\else
Due to lack of space, proofs of these properties are
in the full version of this paper.
\fi

In terms of efficiency, \ourschemelong\ satisfies the following
property:
\begin{theorem}\label{thm:efficiency}
  Let $\underscheme$ be a garbling scheme satisfying the following
  property:
  \begin{itemize}
    \item Let $\cir$ be an arbitrary netlist and let $s$ be the size of
      material generated by invoking $\underscheme.\gGb$ on $\cir$.
      Let both $\underscheme.\gEv$ and $\underscheme.\gGb$, invoked
      on $\cir$, run in $O(s)$ time and $O(s)$ space.
  \end{itemize}
  Then \Cref{ourconstr} instantiated with $\underscheme$ satisfies the
  following property.
  \begin{itemize}
    \item Let $\vec{\cir}$ be a vector of $b$ arbitrary netlists. Let $\nmat$ be
      the maximum size of the garblings constructed by calling
      $\underscheme.\gGb$ on each of these $b$ netlists.
      Then both $\ourscheme.\gEv$ and $\ourscheme.\gGb$, invoked on
      $\conditional(\vec{\cir})$, run in
      $O(\nmat b \log b)$ time and $O(\nmat \log b$) space.
  \end{itemize}
\end{theorem}
Standard garbling schemes, e.g. the
half-gates scheme~\cite{EC:ZahRosEva15}, achieve the efficiency
required by \Cref{thm:efficiency}, since they simply handle each gate
individually.

\iffull
Lemmas that support \Cref{thm:efficiency} are formally stated and proved in
Supplementary Material.
\else
Lemmas that support \Cref{thm:efficiency} are formally stated and
proved in the full version of this paper.
\fi

Proofs of these lemmas follow from inspecting our recursive algorithms
and (1) counting the number of calls to the underlying scheme's
algorithms and (2) counting the number of garblings kept in scope.

We now draw attention to two key details of algorithms in
\Cref{fig:scheme}:
(1) $\ourscheme.\gEv$ delegates to a subprocedure \evcond\ and (2)
$\ourscheme.\gGb$ delegates to a subprocedure \gbcond.
%
All details of conditionals are handled by these two subprocedures.
%
Aside from these delegations, the algorithms in \Cref{fig:scheme} are
relatively unsurprising:
the algorithms closely match \HK's construction and essentially
provide 
%nothing more than 
infrastructure needed to host our contribution.
%
We briefly discuss the most relevant details of these 
%less interesting 
algorithms before returning
to an extended discussion of \evcond\ and \gbcond~(c.f. \Cref{sec:approach-cond}):

\begin{itemize}
  \item \textbf{Projectivity.} \ourschemelong\
    is a \emph{projective garbling scheme}~\cite{CCS:BelHoaRog12}.
    Projectivity requires that the input \emph{encoding string}
    $e$ and output \emph{decoding string} $d$ have a specific format:
    they must both be a vector of pairs of labels such that the left
    element of each pair is a label encoding logical $0$ and the right
    element of each pair is a label encoding $1$.
    Thus, $\ourscheme.\gEn$ and $\ourscheme.\gDe$ are straightforward
    mappings between cleartext values and encoding/decoding strings.
  % \item \textbf{Delegation to \underscheme.} Note that
  %   $\ourscheme.\gev$, $\ourscheme.\gEv$, and $\ourscheme.\gDe$ indeed
  %   directly delegate to \underscheme\ in the case of a netlist.
  \item \textbf{Sequences and Translation.} In a sequence of two
    circuits, all output wires of the first circuit are passed as the inputs
    to the second. Because these two circuits are garbled starting
    from different seeds, the output labels from $\cir_0$ will not match the required
    input encoding of $\cir_1$.
    %
    We thus implement a \emph{translation} component ($\evtranslate$
    and $\gbtranslate$) that implements via garbled rows a
    straightforward translation from one encoding to another.
    %
    Our scheme securely implements the translator, and all other
    gadgets, using a PRF (\HK used an RO).
    %
    This simplification is possible because of the stronger
    property, strong stackability, that we require
    of the underlying garbling scheme~(see \Cref{sec:proof}).
\end{itemize}

\subsection{Algorithms for Handling of Conditionals}\label{sec:approach-cond}

With the remaining formalization out of the way, we focus
on conditional branching. Our goal is to formalize \evcond\
and \gbcond, the key sub-procedures invoked by $\ourscheme.\gEv$ and
$\ourscheme.\gGb$ respectively.
Our presentation is a formalization of discussion in
\Cref{sec:techOverview}; the following explores the technical aspects
of our construction, but the reader should refer to
\Cref{sec:techOverview} for unifying high level intuition.

\subsubsection{Demultiplexer and Multiplexer.}

Before we discuss handling the body of conditionals, we briefly discuss
entering and leaving a conditional.
%
That is, we describe the \emph{demultiplexer} (entry) and
\emph{multiplexer} (exit) components.

The demultiplexer is responsible for (1) forwarding the
conditional's inputs to the active branch $\cir_\aid$ and (2)
forwarding specially prepared garbage inputs to each branch $\cir_{i \neq \aid}$.
The demultiplexer computes the following function for
each wire input $x$ to each branch $\cir_i$ with respect to the active
index \aid:
\begin{align*}
demux(x, i, \aid) =
   \begin{cases}
     x,& \text{if $i = \aid$}\\
     \bot, &\text{otherwise}
   \end{cases}
\end{align*}
where $\bot$ is a specially designated constant value.
In the GC, the label corresponding to $\bot$ is independent yet
indistinguishable from the corresponding $0$ and $1$ labels:
independence is crucial for security.
The demultiplexer is easily implemented by garbled rows.
The number of required rows is proportional to the number of branches
and the conditional's number of inputs.
%
\evcond\ and \gbcond\ make use of \evdem\ and \gbdem, procedures which
implement the above function via GC.
Although we do not, for simplicity, formally describe these, we
emphasize that they are a straightforward implementation of garbled rows.

The multiplexer is central to our approach.
It non-interactively eliminates garbage outputs from inactive
branches.
%
Despite its central role, if \G\ knows the garbage
outputs from each branch, the multiplexer's implementation is simple.
%
Specifically, suppose each branch $\cir_i$ has an output $x_i$ that
should propagate if that branch is active.
The multiplexer computes the following function:
\begin{align*}
  mux(x_0, ..., x_{b-1}, \aid) = x_\aid
\end{align*}
Given that (1) each value $x_{i\neq \aid}$ is a fixed constant $\bot$, at
least with respect to a given \aid\ (a
property that we carefully arrange via the demultiplexer), and (2) \G\
knows the value of each of these fixed constants (the central point of
our work), then the above $mux$ function is easily implemented as a
collection of garbled rows.
The number of required rows is proportional to the number of branches
and the number of the conditional's outputs.
\evcond\ and \gbcond\ make use of \evmux\ and \gbmux, procedures which
implement the above function via GC.
As with the demultiplexer, we do not formalize these procedures in
detail, but their implementation is a straightforward handling of
garbled rows.

\subsubsection{Garbling Subtrees.}
\begin{figure}[t!]\centering\framebox{%
\begin{minipage}{0.97\linewidth}
% \begin{figure}[t]
  \vspace{-12pt}
  \begin{align*}
    &\gbtree(\vec{\cir}, i, j, seed):\\
    &~~\cif~i = j: ~~~\codecomment{Base case of $1$ branch.}\\
    &~~~~\creturn~\gb(\vec\cir[i], seed)\\
    &~~\celse:\\
    &~~~~\codecomment{Expand child seeds using PRF.}\\
    &~~~~seed_L \gets F_{seed}(0)\\
    &~~~~seed_R \gets F_{seed}(1)\\
    &~~~~\codecomment{Recursively garble both child trees and stack
    material.}\\
    &~~~~k \gets \halfway(i, j)\\
    &~~~~M_L, e_L, d_L \gets \gbtree(\vec{\cir}, i, k, seed_L)\\
    &~~~~M_R, e_R, d_R \gets \gbtree(\vec{\cir}, k + 1, j, seed_R)\\
    &~~~~\creturn~(M_L \oplus M_R, e_L \mid e_R, d_L \mid d_R)\\
    \\
    &\halfway(i, j):\\
    &~~\codecomment{Simple helper for splitting range of branches (approximately) in half.}\\
    &~~\creturn~i+\left\lfloor \frac{j-i}{2} \right\rfloor
  \end{align*}
\end{minipage}}
  \caption{%
    The helper algorithm \gbtree\ starts from a single seed
    at the root of a subtree $\node_{i,j}$, derives all seeds in the
    subtree, garbles all branches in the subtree, and stacks (using
    XOR) all resultant material. The procedure also returns the
    input/output encodings for all branches.
  }\label{fig:gbtree}
\end{figure}

Recall, we organize the $b$ branches into a binary tree.
% Both \evcond\ and \gbcond\ frequently perform a common task:
% they garble all branches in an entire subtree and stack together all
% material.
For \emph{each} internal node of the tree, both \evcond\ and \gbcond\
perform a common task: they garble all branches in the entire subtree
rooted at that node and stack together all material.
%
These subtrees are garbled according to seeds given by the
\gadget, formally defined in \Cref{fig:sortinghat}. Like the
demultiplexer and multiplexer, the GC implementation of \gadget\ is
a straightforward handling of garbled rows: we assume procedures
$\gadget.\gEv$ and $\gadget.\gGb$ which implement this handling.
%

We next define a procedure, \gbtree~(\Cref{fig:gbtree}),
which performs the basic task of garbling and stacking an entire
subtree.
%
\gbtree\ recursively descends through the
subtree starting from its root, uses a PRF to derive child seeds from the parent seed, and at the
leaves garbles the branches.
As the recursion propagates back up the tree, the procedure stacks the
branch materials together (and concatenates input/output encodings).
%
The recursion tracks two integers $i$ and
$j$, denoting the range of branches $\cir_i..\cir_j$ that are to
be stacked together.
\evcond\ and \gbcond\ use a similar strategy, and all three algorithms
maintain an invariant that $i,j$ refers to a valid node $\node_{i,j}$ in the binary
tree over the $b$ branches.
%
\evcond\ and \gbcond\ invoke \gbtree\ at
\emph{every} node. This entails that both procedures garble
each branch $\cir_i$ more than once, but with different seeds.
As discussed in \Cref{sec:techOverview}, this repeated garbling is key
to reducing the total number of garbage outputs that \E\
can compute.


\subsubsection{Evaluating Conditionals.}

\begin{figure}
  \begin{align*}
    &\evcond(\vec{\cir}, \mat, X):\\
    &~~b \gets | \vec{\cir} |\\
    &~~\codecomment{Parse the active branch index from the rest of the
    input.}\\
    &~~\aid \mid X' \gets X\\
    &~~\codecomment{Parse material for gadgets and body of conditional.}\\
    &~~\mat_\gadget \mid \mat_{dem} \mid \mat_{cond} \mid \mat_{mux} \gets \mat\\
    &~~\codecomment{Run $\gadget$ to compute all of \E's seeds.}\\
    &~~\es \gets \gadget.\mathtt{Ev}(\aid, \mat_\gadget)\\
    &~~\codecomment{Run the demultiplexer to compute input for each
    branch $\cir_i$.}\\
    &~~\vec{X}_{cond} \gets \evdem(\aid, X, \mat_{dem})\\
    \\
    &~~\codecomment{We define a recursive subprocedure that evaluates $\cir_i - \cir_j$ using material $\mat$.}\\
    &~~\evcond'(i, j, \mat_{i, j}):\\
    &~~~~\cif~i = j:\\
    &~~~~~~\codecomment{Base case: compute output by evaluating the branch normally.}\\
    &~~~~~~\codecomment{This base case corresponds to $\guess = i$.}\\
    &~~~~~~\codecomment{Accumulate output labels into the vector
    $\gcirout_{cond}$ (for later garbage collection).}\\
    &~~~~~~\gcirout_{cond}[i] \gets \ev(\cir_i, M, \gcirinp_{cond}[i])\\
    &~~~~\celse:\\
    &~~~~~~k \gets \halfway(i, j)\\
    &~~~~~~\codecomment{Garble the right subtree using the available
    seed,}\\
    &~~~~~~\codecomment{unstack, and recursively evaluate the left
    subtree.}\\
    &~~~~~~\mat_{k+1,j}, \cdot, \cdot \gets \gbtree(\vec{\cir}, k+1, j, \es_{k+1, j})\\
    &~~~~~~\evcond'(i, k, \mat_{i, j} \oplus \mat_{k+1,j})\\
    &~~~~~~\codecomment{Symmetrically evaluate the right subtree.}\\
    &~~~~~~\mat_{i, k}, \cdot, \cdot \gets \gbtree(\vec{\cir}, i, k, \es_{i,k})\\
    &~~~~~~\evcond'(k+1, j, \mat_{i, j} \oplus \mat_{i, k})\\
    \\
    &~~\codecomment{Start recursive process from the top of the tree.}\\
    &~~\evcond'(0, b-1, M_{cond})\\
    &~~\codecomment{Eliminate garbage and propagate $\vec{Y}_\aid$ via
    the multiplexer.}\\
    &~~\creturn~\evmux(\aid, \vec{Y}_{cond}, M_{mux})
  \end{align*}
  \caption{%
    \E's procedure, \evcond, for evaluating a conditional with $b$ branches.
    \evcond\ evaluates each branch; $b-1$ evaluations
    result in garbage outputs and one (the evaluation of
    $\cir_\aid$) results in valid outputs.
    The multiplexer collects garbage and propagates output from
    $\cir_\aid$.
    \evcond\ involves $b \log b$ calls to \gGb\ (via \gbtree), and each
    branch evaluation is done with respect to the garbling of that
    branch's sibling subtrees.
  }\label{fig:evcond}
\end{figure}

We now formalize the procedure \evcond\ by which \E\ handles a vector of
conditionals~(\Cref{fig:evcond}).
%
The core of \evcond\ is delegated to a recursive subprocedure $\evcond'$.
$\evcond'$ carefully manages material and uses the garblings of sibling
subtrees to evaluate each branch while limiting the possible number of
garbage outputs.
$\evcond'$ is a formalization of the high level procedure described in
\Cref{sec:techOverview}: \E\ recursively descends through the tree,
constructing and unstacking garblings of subtrees in the general case.
%
When she finally reaches the leaf nodes, she simply evaluates.
%
In the base case $i = \aid$, she will have correctly unstacked all
material except $\mat_\aid$ (because she has good seeds for the
sibling roots of \aid), and hence evaluates correctly.
%
All other cases $i \neq \aid$ will lead to garbage outputs that \G\
must also compute.
Other than the delegation to $\evcond'$, \evcond\ simply invokes $\gadget.\gEv$
to obtain her seeds, invokes \evdem\ to propagate valid inputs to $\cir_\aid$,
and, after evaluating all branches, invokes $\evmux$ to collect
garbage outputs from all $\cir_{i \neq \aid}$.
%

\subsubsection{Garbling Conditionals.}
\begin{figure}[t!]\centering\framebox{%
\begin{minipage}{0.97\linewidth}
  \vspace{-12pt}
  \begin{align*}
    &\gbcond(\vec{\cir}, S):\\
    &~~b \gets | \vec{\cir} |\\
    &~~\codecomment{Recursively derive all `good' seeds for the entire tree.}\\
    &~~s \gets \mathtt{DeriveSeedTree}(S, b)\\
    &~~\codecomment{Sample input/output encodings for the conditional.}\\
    &~~e \gets \genprojection(S, \inpsize(\conditional(\vec{\cir})))\\
    &~~d \gets \genprojection(S, \outsize(\conditional(\vec{\cir})))\\
    &~~\codecomment{Parse encoding into encoding of $\aid$
    and encoding of rest of input.}\\
    &~~e_\aid\mid e' \gets e\\
    &~~\codecomment{Garble \gadget\ based on the encoding of \aid.}\\
    &~~\codecomment{This outputs material as well as the tree of all
    `bad' seeds $s'$.}\\
    &~~\mat_\gadget, s' \gets \gadget.\mathtt{Gb}(e_\aid, s)\\
    &~~\codecomment{Construct the stacked material and input encodings for each branch.}\\
    &~~M_{cond}, e_{cond}, d_{cond} \gets \gbtree(\vec{\cir}, 0, b-1, s_{0, b-1})\\
    &~~\codecomment{The demux conditionally translates the input encoding $e'$}\\ 
    &~~\codecomment{to one of the branch encodings in $e_{cond}$ based on $e_\aid$.}\\
    &~~\mat_{dem}, \Lambda_{in} \gets \gbdem(e_\aid, e', e_{cond})\\
    &~~\codecomment{Compute all possible garbage outputs.}\\
    &~~\Lambda_{out} \gets \computegarbage(\vec{\cir}, M_{cond}, \Lambda_{in}, s, s')\\
    &~~\codecomment{The demultiplexer collects garbage outputs.}\\
    &~~\mat_{mux} \gets \gbmux(e_\aid, d, d_{cond}, \Lambda_{out})\\
    &~~\creturn~(\mat_\gadget \mid \mat_{dem} \mid \mat_{cond} \mid
    \mat_{mux}, e, d)
\end{align*}
\end{minipage}}
  \caption{%
    The algorithm for garbling a conditional vector.
    Given $b$ branches, \gbcond\ returns (1) the stacked material, (2)
    the input encoding string, (3) all $b$ output decoding strings,
    and (4) all $b\log b$ possible garbage output label vectors.
  }\label{fig:gbcond}
\end{figure}


\begin{figure}
  \begin{align*}
    &\computegarbage(\vec{\cir}, \mat, \Lambda_{in}, s, s'):\\
    &~~\codecomment{We first define a recursive subprocedure.}\\
    &~~\computegarbage'(i, j, \mat_{i,j}, \vec{\mat}'):\\
    &~~~~\codecomment{Compute all possible garbage outputs from
    branches $\cir_i-\cir_j$.}\\
    &~~~~\codecomment{$\vec{\mat}'$ is a vector of the bad garblings of
      all sibling roots of the current node.}\\
    &~~~~\cif~i = j:\\
    &~~~~~~\codecomment{Base case: loop over all possible garbage material}\\
    &~~~~~~\codecomment{and accumulate garbage outputs into
    $\Lambda_{out}$.}\\
    &~~~~~~acc \gets \mat_{i,i}\\
    &~~~~~~\cfor~k \in 0..|\vec{\mat}'|-1:\\
    &~~~~~~~~\codecomment{Emulate all possible bad evaluations of $\cir_i$.}\\
    &~~~~~~~~acc \gets acc \oplus \vec{\mat}'[k]\\
    &~~~~~~~~\Lambda_{out}[i][k] \gets \gEv(\vec{\cir}[i], acc, \Lambda_{in}[k])\\
    &~~~~\celse:\\
    &~~~~~~k \gets \halfway(i, j)\\
    &~~~~~~\codecomment{Compute the good material for both subtrees.}\\
    &~~~~~~\mat_{i, k}, \cdot, \cdot \gets \gbtree(\vec{\cir}, i, k, s_{i, k})\\
    &~~~~~~\mat_{k+1, j} \gets \mat_{i, j} \oplus \mat_{i, k}\\
    &~~~~~~\codecomment{Compute the bad material for both subtrees.}\\
    &~~~~~~\mat_{i, k}', \cdot, \cdot \gets \gbtree(\vec{\cir}, i, k, s'_{i, k})\\
    &~~~~~~\mat_{k+1, j}', \cdot, \cdot \gets \gbtree(\vec{\cir}, k+1, j, s'_{k+1, j})\\
    &~~~~~~\codecomment{Recursively compute all garbage outputs.}\\
    &~~~~~~\computegarbage'(i, k, (\mat_{k+1,j} \oplus \mat_{k+1,j}') \mid \vec{\mat}')\\
    &~~~~~~\computegarbage'(k+1, j, (\mat_{i,k} \oplus \mat_{i,k}') \mid \vec{\mat}')\\
    \\
    &~~b \gets |\vec{\cir}|\\
    &~~\codecomment{Start the recursive process using the top level material $\mat$}\\
    &~~\codecomment{and using the empty vector of bad sibling material.}\\
    &~~\computegarbage'(0, b-1, \mat, [~])\\
    &~~\creturn~\Lambda_{out}
  \end{align*}
  \caption{%
    \computegarbage\ allows \G\ to compute the possible garbage output labels
    from evaluation of inactive branches.
    Specifically, the algorithm takes as arguments (1) the vector of
    conditional branches $\vec{\cir}$, (2) the `good' material for the
    conditional $M$, (3) the garbage input labels $\Lambda_{in}$, (4)
    the tree of `good' seeds (i.e. the seeds used by \G\ to generate
    $M$) $s$, and (5) the tree of `bad' seeds $s'$.
    The algorithm outputs $\Lambda_{out}$, the vector (length $b$) of
    vectors (each length $\log b$) of output labels from each
    branch.
  }\label{fig:computegarbage}
\end{figure}

Finally, we formalize \G's procedure for handling vectors of
conditional branches, \gbcond~(\Cref{fig:gbcond}).
%
\begin{enumerate}
  \item \gbcond\ recursively derives a binary tree of
good seeds via $\mathtt{DeriveSeedTree}$. This call uses a PRF
to recursively derive seeds in the standard manner.
%
\item \gbcond\ invokes $\genprojection$ to select uniform input/output
encodings $e$ and $d$: $e$ and $d$ are vectors of pairs of labels that are
the valid input/output labels for the overall conditional.
Our use of $\genprojection$ is straightforward and similar to that of
\HK.
% $\genprojection$ is semantically and technically the same as defined
% in \HK.
%
\item \gbcond\ uses $\gadget.\gGb$ to garble the \gadget\
  functionality of \Cref{fig:sortinghat}.
  As input, \gbcond\ provides the tree of good seeds $s$ and the encoding
  of the active branch id $e_\aid$. As output, \G\ receives the tree
  of all bad seeds.
  \gbcond\ needs these bad seeds, in addition to the good seeds he
  already knows, to emulate \E\ making a bad guess.
%
\item \gbcond\ uses $\gbtree$ to derive stacked material
$\mat_{cond}$ from the root seed.
$\mat_{cond}$ is the material that \G\ ultimately sends to \E.
%
\item \gbcond\ calls $\gbdem$ to compute the demultiplexer garbled
  rows.  This call also returns $\Lambda_{in}$, the collection of garbage input labels for each
  branch: essential information that allows \G\ to emulate \E.
\end{enumerate}
With this accomplished, \gbcond's remaining task is to encrypt the
garbage-collecting multiplexer.
However, it is not clear how
this can be achieved unless \G\ \emph{knows all garbage outputs} that
\E\ might compute.
%
Thus, \gbcond\ first invokes \computegarbage\
(\Cref{fig:computegarbage}), a procedure which
emulates all of \E's bad guesses.

\computegarbage\ delegates to the recursive subprocedure
$\computegarbage'$. This recursive procedure walks down the tree,
maintaining two key variables: (1) $\mat_{i,j}$ holds the correct
material for the current subtree $\node_{i,j}$ and (2) $\vec{\mat}'$
holds a vector of bad materials of the incorrectly garbled sibling
roots of $\node_{i,j}$.
%
In the general case, these variables are simply appropriately updated
via calls to $\gbtree$.
Thus,
in the base case, the garbage materials for all sibling roots of the
considered leaf are available.
Additionally, all garbage inputs into each branch are available in the
vector $\Lambda_{in}$.
%
So, at the leaves we can compute all garbage outputs for each
branch by calling \gEv\ on the proper combinations of garbage material
and labels.
%
We store all garbage outputs into the global vector $\Lambda_{out}$, which is
returned by the overall procedure, and then ultimately used by
\gbcond\ to call $\gbmux$.
