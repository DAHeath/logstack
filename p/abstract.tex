\begin{abstract}
  Secure two party computation (2PC) of arbitrary programs can be
  efficiently achieved using garbled circuits (GC).
  Until recently, it was widely believed that a GC
  proportional to the entire program, including parts of the program
  that are entirely discarded due to conditional branching, must
  be transmitted over a network.
  Recent work shows that this belief is \emph{false}, and that
  communication proportional only to the longest program execution
  path suffices (Heath and Kolesnikov, CRYPTO 20, \HK).
  Although this recent work reduces needed communication, it
  \emph{increases} computation.
  For a conditional with $b$ branches, the players use $O(b^2)$
  computation (traditional GC uses only $O(b)$).

\smallskip
  %We extend  \HK 
  Our scheme \ourschemelong  reduces stacked garbling computation from
  $O(b^2)$ to $O(b \log b)$
   with {\em no} increase in communication over \HK.
   % \vlad{our gadget is slightly larger than HK.}
  The cause of \HK's increased computation is the
  oblivious collection of \emph{garbage labels} that emerge during the
  evaluation of inactive branches.
  Garbage is collected by a \emph{multiplexer} that is
  costly to generate.
  At a high level, we redesign stacking and garbage collection
  to avoid quadratic scaling.

  \smallskip
  Our construction is also more {\em space
  efficient}: \HK algorithms require $O(b)$ space, while ours use only
  $O(\log b)$ space.
  This space efficiency allows even modest setups to handle large numbers of branches.
  % require storing material of each of $b^2$
  % circuits, we only need $O(|C| \log b)$ RAM.  \vlad{correct?  Also,
  % number of RAM accesses?}
  % This further significantly improves the advantage of our scheme.
  
  %\smallskip
  %We discuss applicability of our improvement to general functions, including ones with narrow branching.  High performance of \ourschemelong opens rich opportunity for performance-improving program transformations which may dramatically increase  the branching factor and use of branching.
%\smallskip
%%\vlad{We should say smth in main about known schemes fitting into the assumptions we made.}
%%	Further,  for a natural class of garbling schemes, which includes all popular schemes, such as half-gates, this performance is near optimal.  We show that stacked garbling schemes making a linear in $b$ number of calls to garble (resp. evaluate) must make a quadratic in $b$ number of calls to evaluate (resp. garble).
%\vlad{removed LB claims}

\smallskip
\HK assumes a random oracle (RO).
We track the source of this need,
formalize a simple and natural added assumption on the base garbling
scheme,
and remove reliance on RO:
% that allows to remove
% reliance on RO.
\ourschemelong  is secure in the standard model.
Nevertheless, \ourschemelong can be instantiated with typical GC
tricks based on non-standard assumptions, such as free XOR and half-gates,
and hence can be implemented with high efficiency.
% It
% can be instantiated more efficiently in the stronger
% RO model.

\smallskip	
We implemented \ourschemelong (in the RO model, based on half-gates
garbling) and report performance.
In terms of wall-clock time and for fewer than $16$ branches, our performance is comparable to \HK's; for larger branching factors, our
approach clearly outperforms \HK.
For example, given $1024$ branches, our approach is $31\times$ faster.
% It improves over \HK\ by factor xx.
\end{abstract}
